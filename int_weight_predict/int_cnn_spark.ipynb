{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 尝试写一个整形权重CNN的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb 1\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)  # for reproducibility\n",
    "nb_classes = 34\n",
    "nb_epoch = 30\n",
    "batch_size = 128\n",
    "\n",
    "image_higth, image_width = 15, 15\n",
    "# lr = [0.05, 0.01, 0.005]\n",
    "layer1 = 10\n",
    "hidden1 = 40\n",
    "region = 3\n",
    "\n",
    "# 模型权重根目录\n",
    "model_root_path = '/home/jdwang/PycharmProjects/digitRecognition/int_weight_predict/modelAndData1122/'\n",
    "model_file_list_path = os.listdir(os.path.join(model_root_path, 'model'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义必要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_valdata(version='1122'):\n",
    "    \"\"\"读取不同版本的测试集\n",
    "    1120 - 对应 /home/jdwang/PycharmProjects/digitRecognition/int_weight_predict/modelAndData1120/Data/\n",
    "    1122 - 对应 /home/jdwang/PycharmProjects/digitRecognition/int_weight_predict/modelAndData1122/Data/\n",
    "\n",
    "    :param dir_path: str\n",
    "    :param version: str\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # 数据集根目录\n",
    "    data_root_path = '/home/jdwang/PycharmProjects/digitRecognition/int_weight_predict/'\n",
    "\n",
    "    # 读取验证数据、测试数据\n",
    "    if version == '1122':\n",
    "        val_file_path = os.path.join(data_root_path, 'modelAndData1122/Data/', 'TrainSet_trainAndVal_testSet.pickle')\n",
    "        other_file_path = os.path.join(data_root_path, 'modelAndData1122/Data/', 'Olddata_TestSet.pickle')\n",
    "        with open(val_file_path, 'rb') as train_file:\n",
    "            train_X = pickle.load(train_file)\n",
    "            train_y = pickle.load(train_file)\n",
    "            val_X, val_y = None, None\n",
    "            test_X = pickle.load(train_file)\n",
    "            test_y = pickle.load(train_file)\n",
    "    elif version == '1120':\n",
    "        val_file_path = os.path.join(data_root_path, 'modelAndData1120/Data/', 'valSet&TestSet.pickle')\n",
    "        other_file_path = os.path.join(data_root_path, 'modelAndData1120/Data/', 'Olddata_TestSet.pickle')\n",
    "        with open(val_file_path, 'rb') as train_file:\n",
    "            val_X = pickle.load(train_file)\n",
    "            val_y = pickle.load(train_file)\n",
    "            test_X = pickle.load(train_file)\n",
    "            test_y = pickle.load(train_file)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    with open(other_file_path, 'rb') as otherFile:\n",
    "        other_X = pickle.load(otherFile)\n",
    "        other_y = pickle.load(otherFile)\n",
    "\n",
    "    return (val_X, val_y), (test_X, test_y), (other_X, other_y)\n",
    "\n",
    "\n",
    "def Net_model(layer1, hidden1, region, rows, cols, nb_classes, lr=0.01, decay=1e-6, momentum=0.9):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "    from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "    from keras.optimizers import SGD\n",
    "    from keras import backend as K\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(layer1, region, region,\n",
    "                            border_mode='valid',\n",
    "                            input_shape=(1, rows, cols)))\n",
    "\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())  # 平铺\n",
    "\n",
    "    model.add(Dense(hidden1))  # Full connection 1:  1000\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # 获取CNN的中间结果\n",
    "    mid_output = K.function(inputs=[\n",
    "        model.layers[0].input,\n",
    "        K.learning_phase(),\n",
    "    ],\n",
    "        outputs=[\n",
    "            model.layers[-9].output,\n",
    "            model.layers[-8].output,\n",
    "            model.layers[-7].output,\n",
    "            model.layers[-6].output,\n",
    "            model.layers[-5].output,\n",
    "            model.layers[-4].output,\n",
    "            model.layers[-3].output,\n",
    "            model.layers[-2].output,\n",
    "            model.layers[-1].output,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sgd = SGD(lr=lr, decay=decay, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model, mid_output\n",
    "\n",
    "\n",
    "def test_model(model_file, X_test, Y_test):\n",
    "    # 加载模型架构\n",
    "    # 这里的 lr 设置什么不影响\n",
    "    model, mid_output = Net_model(layer1, hidden1, region, image_higth, image_width, nb_classes=34, lr=0)\n",
    "    model.load_weights(model_file)\n",
    "\n",
    "    # 预测\n",
    "    predicted = model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "    return count_result(predicted, Y_test)\n",
    "\n",
    "\n",
    "def count_result(predicted, Y_test):\n",
    "    '''统计预测情况，包括混淆集个数等\n",
    "\n",
    "    :return:\n",
    "    '''\n",
    "    # 统计混淆集\n",
    "    badcase = {}\n",
    "    for i in range(0, len(Y_test)):\n",
    "        if (tramsform(predicted[i]) in ['1', 'I'] and tramsform(Y_test[i]) in ['1', 'I']):\n",
    "            # 1跟I区分，只要 是 测试 成1或I，而实际值是 1或I都算对\n",
    "            predicted[i] = Y_test[i]\n",
    "        if predicted[i] != Y_test[i]:\n",
    "            ch1 = tramsform(Y_test[i])\n",
    "            ch2 = tramsform(predicted[i])\n",
    "            string = ','.join(sorted([ch1, ch2]))\n",
    "\n",
    "            if badcase.has_key(string):\n",
    "                badcase[string] += 1\n",
    "            else:\n",
    "                badcase[string] = 1\n",
    "\n",
    "    # 计算测试准确率\n",
    "    test_accuracy = np.mean(np.equal(predicted, Y_test))\n",
    "    graterThan2 = 0\n",
    "    graterThan5 = 0\n",
    "    graterThan10 = 0\n",
    "    for key, value in badcase.items():\n",
    "        if value >= 2:\n",
    "            graterThan2 += 1\n",
    "        if value >= 5:\n",
    "            graterThan5 += 1\n",
    "        if value >= 10:\n",
    "            graterThan10 += 1\n",
    "\n",
    "    return test_accuracy, graterThan2, graterThan5, graterThan10, badcase\n",
    "\n",
    "\n",
    "def tramsform(num):\n",
    "    \"\"\" 数字 转换成 字符\n",
    "\n",
    "    :param num:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if num < 10:\n",
    "        return str(num)\n",
    "    else:\n",
    "        if num >= 24:\n",
    "            num += 1\n",
    "        if num >= 31:\n",
    "            num += 1\n",
    "        return chr(ord('A') + num - 10)\n",
    "\n",
    "\n",
    "def conv_pool_operation(img, conv_W, conv_b):\n",
    "    \"\"\"CNN 卷积 和 池化操作\n",
    "        一张图片\n",
    "    :param img: array-3D\n",
    "        一张图片，3D，(num_of_channels,img_height,img_width)\n",
    "    :param conv_W: array-4D\n",
    "        10*3*3\n",
    "    :param conv_b:\n",
    "    :return: array-3D\n",
    "    \"\"\"\n",
    "    filter_row, filter_col = conv_W.shape[2:]\n",
    "    img_row, img_col = img.shape[1:]\n",
    "    # convolution\n",
    "    # 3D\n",
    "    conv_result = np.zeros((conv_W.shape[0], img_row - filter_row + 1, img_col - filter_col + 1))\n",
    "    # quit()\n",
    "    for filter_index in range(conv_W.shape[0]):\n",
    "        j = conv_W[filter_index, 0].flatten()[-1::-1]\n",
    "        for x in range(0, img_row - filter_row + 1):\n",
    "            for y in range(0, img_col - filter_col + 1):\n",
    "#                 i = img[0, x:x + filter_row, y:y + filter_col].flatten()\n",
    "#                 \n",
    "                conv_result[filter_index,\n",
    "                            x,\n",
    "                            y] = tanh_approximate_function(\n",
    "                    np.dot(\n",
    "                        img[0, x:x + filter_row, y:y + filter_col].flatten(), \n",
    "                        j\n",
    "                    ) \n",
    "                    + conv_b[filter_index]\n",
    "                )\n",
    "                # print(np.dot(i, j) + conv_b[filter_index])\n",
    "\n",
    "    # conv_result = tanh_approximate_function(conv_result)\n",
    "    pool_row, pool_col = 2, 2\n",
    "    pool_result = np.zeros(\n",
    "        (conv_result.shape[0], conv_result.shape[1] / pool_row, conv_result.shape[2] / pool_col))\n",
    "    # max-pooling\n",
    "    for channel_index in range(pool_result.shape[0]):\n",
    "        for x in range(pool_result.shape[1]):\n",
    "            for y in range(pool_result.shape[2]):\n",
    "                pool_result[\n",
    "                    channel_index,\n",
    "                    x,\n",
    "                    y\n",
    "                ] = np.max(\n",
    "                    conv_result[\n",
    "                    channel_index,\n",
    "                    x * pool_row: (x + 1) * pool_row,\n",
    "                    y * pool_col: (y + 1) * pool_col\n",
    "                    ])\n",
    "    return pool_result\n",
    "\n",
    "\n",
    "def hidden_operation(feature_vector, W, b, activion='tanh'):\n",
    "    \"\"\" 隐含层操作\n",
    "\n",
    "    :param activion: str\n",
    "        激活函数\n",
    "    :param feature_vector: array-like\n",
    "        一张 图片的 feature vector，1D\n",
    "    :param W: array-2D\n",
    "        权重\n",
    "    :param b: array-1D\n",
    "        偏差\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    if activion == 'tanh':\n",
    "        # return np.asarray([tanh_approximate_function(item) for item in temp])\n",
    "        return map(lambda x: tanh_approximate_function(np.dot(feature_vector, x[0]) + x[1]), zip(W.transpose(), b))\n",
    "    elif activion == 'none':\n",
    "        # return temp\n",
    "        return map(lambda x:np.dot(feature_vector, x[0])+x[1], zip(W.transpose(),b))\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def tanh_approximate_function(x):\n",
    "    \"\"\"\n",
    "         * tanh x=sinh x / cosh x\n",
    "         * 其中sinh x=(e^(x)-e^(-x))/2 ，cosh x=(e^x+e^(-x))/2\n",
    "         * 所以tanhx = (e^(x)-e^(-x)) /(e^x+e^(-x))\n",
    "    \"\"\"\n",
    "    #     return (int)(tanh(x));\n",
    "\n",
    "    if x > 10:\n",
    "        return 1\n",
    "    elif x < -10:\n",
    "        return -1\n",
    "    else:\n",
    "        return (int)((np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x)))\n",
    "\n",
    "\n",
    "def cnn_batch_predict(X_val, weights):\n",
    "    '''CNN批量预测\n",
    "\n",
    "    :param X_val:\n",
    "    :param weights:\n",
    "    :return:\n",
    "    '''\n",
    "    weights = [(item * 1e6).astype(dtype=int) for item in weights]\n",
    "    # result = cnn_predict(X_val[0],weights)\n",
    "    result = []\n",
    "    for index, img in enumerate(X_val):\n",
    "        if (index + 1) % 1000 == 0:\n",
    "            print('%d' % (index + 1))\n",
    "        result.append(cnn_predict(img, weights))\n",
    "    return np.asarray(result)\n",
    "\n",
    "\n",
    "def cnn_predict(img, weights):\n",
    "    '''单张图片的预测\n",
    "\n",
    "    :param img:\n",
    "    :param weights:\n",
    "    :return:\n",
    "    '''\n",
    "    # 3D\n",
    "    %time imgs_conv_result = conv_pool_operation(img, weights[0], weights[1])\n",
    "    # print('conv over..')\n",
    "    %time flatten_result = imgs_conv_result.flatten()\n",
    "    # print('flatten over..')\n",
    "    # print(flatten_result.shape)\n",
    "    %time hidden1_output = hidden_operation(flatten_result, weights[2], weights[3], activion='tanh')\n",
    "\n",
    "    # print('hidden1 over..')\n",
    "    %time hidden2_output = hidden_operation(hidden1_output, weights[4], weights[5], activion='none')\n",
    "    # print('hidden2 over..')\n",
    "    # print(hidden2_output.shape)\n",
    "    result = np.argmax(hidden2_output)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def cnn_batch_predict_spark(X_val_rdd,y_val, weights):\n",
    "    weights = [(item * 1e5).astype(dtype=int) for item in weights]\n",
    "#     result_rdd = X_val_rdd.map(lambda x:cnn_predict(x,weights))\n",
    "    \n",
    "    result_rdd = X_val_rdd.map(lambda x:conv_pool_operation(x, weights[0], weights[1]))\\\n",
    "    .map(lambda x: x.flatten())\\\n",
    "    .map(lambda x:hidden_operation(x,weights[2], weights[3],activion='tanh'))\\\n",
    "    .map(lambda x:hidden_operation(x,weights[4], weights[5],activion='none'))\\\n",
    "    .map(np.argmax)\n",
    "    \n",
    "# #     result_rdd.cache()\n",
    "    result = result_rdd.collect()\n",
    "#     accu = np.mean(np.asarray(result) == y_val) \n",
    "# #     print(accu)\n",
    "    return result,count_result(result,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64381, 1, 15, 15)\n",
      "(243391, 1, 15, 15)\n",
      "CPU times: user 3.39 s, sys: 268 ms, total: 3.66 s\n",
      "Wall time: 3.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# region 读取数据集：验证数据(64369个)、测试数据(64381个)、其他应用数据集(243391个)\n",
    "(X_val, y_val), (X_test, y_test), (X_other, y_other) = load_valdata(version='1122')\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_other.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将图片数据序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 ms, sys: 44 ms, total: 88 ms\n",
      "Wall time: 504 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 测试集\n",
    "X_val_rdd = sc.parallelize(X_test)\n",
    "y_val = y_test\n",
    "X_val_rdd.cache\n",
    "\n",
    "# 应用集\n",
    "X_other_rdd = sc.parallelize(X_other)\n",
    "y_other = y_other\n",
    "\n",
    "X_other_rdd.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 保存34分类TOP21的测试集预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.999565089079 8 0 0\n",
      "{'3,8': 2, '7,T': 1, '0,Q': 2, '7,P': 1, '1,7': 3, '1,T': 3, 'C,G': 1, '5,6': 2, '8,B': 1, '3,S': 2, 'X,Y': 1, '4,A': 1, '0,D': 1, '0,C': 1, '5,L': 2, '2,Z': 2, 'G,Q': 1, 'H,K': 1}\n",
      "129 0.999580621612 6 1 0\n",
      "{'9,S': 1, '0,Q': 1, 'H,W': 1, 'F,P': 1, '1,T': 2, '5,6': 1, '8,B': 4, '6,G': 4, '5,U': 2, 'D,Q': 1, '0,D': 5, 'A,X': 1, '2,Z': 2, 'C,Q': 1}\n",
      "141 0.999720414408 6 0 0\n",
      "{'A,N': 1, '6,K': 1, '0,Q': 2, 'E,F': 2, 'C,G': 1, '5,6': 4, 'F,P': 1, '6,8': 2, '0,D': 2, '2,Z': 2}\n",
      "245 0.999487426415 10 1 0\n",
      "{'6,E': 1, '1,X': 1, '0,Q': 5, '1,7': 3, '1,4': 3, 'C,G': 1, '5,6': 2, '0,G': 2, '6,8': 2, '0,D': 3, '0,C': 1, '8,Y': 1, 'F,P': 2, '5,B': 1, '5,S': 1, '1,T': 2, '3,B': 2}\n",
      "249 0.999658284276 6 0 0\n",
      "{'9,S': 1, '5,S': 1, '8,B': 1, '5,U': 2, '0,G': 2, '4,A': 4, '0,D': 3, '0,C': 2, '2,Z': 3, '6,F': 1, 'C,Q': 1, '3,9': 1}\n",
      "270 0.999580621612 7 2 0\n",
      "{'7,Z': 1, '3,8': 2, '0,Q': 2, '2,E': 2, '1,7': 5, '2,Z': 2, '8,B': 1, '6,F': 1, 'F,H': 1, '0,D': 6, '5,L': 2, '5,S': 1, 'G,Q': 1}\n",
      "287 0.999642751744 7 1 0\n",
      "{'0,Q': 6, 'F,P': 1, '1,T': 3, '8,B': 2, '5,U': 2, '0,G': 2, '6,8': 1, '0,D': 2, '0,C': 2, 'B,R': 1, 'K,X': 1}\n",
      "300 0.999440828816 10 2 0\n",
      "{'F,P': 3, '5,S': 2, '1,T': 1, 'C,G': 1, '5,6': 1, '8,B': 1, '5,U': 2, 'F,J': 2, 'G,U': 1, '0,D': 5, '0,C': 3, '2,Z': 2, '5,B': 1, '1,G': 2, 'M,Y': 4, '2,P': 5}\n",
      "311 0.999642751744 6 1 0\n",
      "{'C,G': 2, '3,8': 2, '0,Q': 3, '6,B': 1, '5,6': 1, '8,B': 1, '0,G': 2, '0,D': 6, '5,N': 2, 'X,Y': 1, '2,Z': 1, 'B,D': 1}\n",
      "375 0.999611686678 7 0 0\n",
      "{'7,T': 1, 'P,R': 1, '0,Q': 1, '1,7': 1, '1,T': 3, '5,6': 1, '8,B': 4, '6,8': 3, '0,D': 3, '9,B': 1, '5,L': 2, '2,Z': 2, '8,S': 2}\n",
      "425 0.999363166152 8 3 1\n",
      "{'9,S': 1, '0,Q': 4, '5,S': 1, '1,T': 2, 'C,G': 5, '5,6': 10, '8,B': 3, 'F,P': 1, '4,A': 1, '0,D': 7, '1,J': 1, '2,Z': 3, 'N,W': 2}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 34分类前21个模型的预测结果\n",
    "predict_result_34class_file = open(os.path.join(model_root_path,'34class_test_predict_result_e5.pkl'),'w')\n",
    "\n",
    "# TOP21个模型的编号\n",
    "run_id = [99,129,141,245,249,270,287,300,311,375,425,509,543,630,758,864,875,890,905,975,1014]\n",
    "run_idx = 0\n",
    "with open(os.path.join(model_root_path, '34class_model_weight.pkl'), 'r') as fin:\n",
    "    for index in range(1, len(model_file_list_path) + 1):\n",
    "        # 从 模型1 开始，依次往后\n",
    "        # 找到对应模型文件\n",
    "#         if index != run_id[run_idx]:\n",
    "#             weights = pickle.load(fin)\n",
    "#             continue\n",
    "        \n",
    "        if index < run_id[run_idx]:\n",
    "            weights = pickle.load(fin)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        weights = pickle.load(fin)\n",
    "\n",
    "        # print('OK')\n",
    "        int_predict,(test_accuracy, graterThan2, graterThan5, graterThan10,badcase) = \\\n",
    "        cnn_batch_predict_spark(X_val_rdd,y_val, weights)\n",
    "        \n",
    "        print(index,test_accuracy, graterThan2, graterThan5,graterThan10)\n",
    "        print(badcase)\n",
    "        \n",
    "        pickle.dump(np.asarray(int_predict),\n",
    "                    predict_result_34class_file\n",
    "                   )\n",
    "\n",
    "        \n",
    "#         print(test_accuracy, graterThan5, graterThan10)\n",
    "        run_idx += 1\n",
    "        if run_idx>=len(run_id):\n",
    "            break\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 整理下badcase混淆集情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s='''{'0,6': 4, '1,9': 1, '1,4': 1, '6,8': 7, 'H,K': 2, '5,8': 3, '3,8': 4, '5,6': 8, 'G,Q': 5, '8,L': 1, '9,S': 4, '7,P': 1, '7,T': 1, '8,B': 34, '4,A': 2, '9,H': 5, '0,Q': 7, '1,T': 14, 'C,G': 4, '6,E': 6, '0,D': 30, '0,C': 5, '2,Z': 20, 'B,G': 2, '1,B': 2}\n",
    "{'D,Q': 2, '4,Q': 1, '6,E': 1, '0,Q': 17, 'B,Z': 2, '1,7': 9, '1,T': 1, '5,6': 6, '8,B': 12, '6,G': 4, '6,8': 4, '4,A': 2, '0,D': 36, '9,B': 2, '2,Z': 1}\n",
    "{'J,T': 2, '7,Z': 2, '0,4': 1, '3,8': 3, '9,S': 2, '0,Q': 6, '1,Y': 2, 'E,F': 1, '1,7': 1, '1,T': 2, '5,6': 22, '8,B': 11, '6,8': 1, '0,D': 21, '0,C': 5, 'F,P': 1, '5,S': 3, '3,B': 3}\n",
    "{'1,7': 9, '6,8': 5, '3,8': 3, '4,6': 4, 'F,P': 3, '5,6': 19, '3,B': 7, 'G,Q': 1, '9,S': 2, '7,T': 2, '8,B': 5, '4,A': 3, '5,B': 1, '4,M': 1, '0,Q': 12, '1,Y': 3, 'C,D': 1, '1,W': 2, '1,T': 2, 'C,G': 1, '0,D': 40, '0,C': 1}\n",
    "{'7,T': 2, '9,P': 2, '0,Q': 7, '6,E': 2, '1,T': 11, '5,6': 4, '8,B': 5, '6,G': 2, 'C,Q': 3, '0,G': 2, 'F,P': 1, '4,A': 5, '0,D': 9, '0,C': 2, 'G,Q': 1, '2,Z': 9, '5,B': 2, '3,8': 3, '1,4': 1}\n",
    "{'J,T': 6, '0,3': 2, '1,7': 25, '6,8': 2, '2,9': 1, '3,8': 5, '5,6': 2, 'G,Q': 2, 'K,Y': 1, '9,S': 5, '7,T': 2, '8,B': 8, '9,B': 2, '9,J': 2, '0,Q': 4, 'C,D': 2, '1,T': 20, 'C,G': 1, '6,E': 3, '6,F': 2, '0,D': 37, '0,C': 19, 'E,S': 3}\n",
    "{'0,4': 1, 'E,F': 1, '6,8': 3, '5,9': 3, 'F,P': 1, '5,6': 8, '1,7': 3, 'G,Q': 1, 'K,X': 1, '4,Q': 1, '9,S': 2, '7,T': 13, '8,B': 36, '9,E': 8, '5,F': 5, '3,B': 2, '0,Q': 52, '1,T': 6, '6,E': 3, 'B,P': 2, '6,G': 2, 'B,R': 2, '0,G': 4, '0,D': 57, '0,C': 19, '0,L': 3}\n",
    "{'1,7': 3, '6,8': 2, '5,9': 4, 'F,P': 4, '5,6': 4, 'F,J': 2, '4,M': 1, 'N,X': 3, 'M,Y': 7, 'G,U': 2, '7,Z': 1, '9,S': 5, '8,B': 37, '4,A': 1, '9,B': 2, 'R,Z': 2, '5,B': 1, '5,F': 2, '3,B': 2, '0,Q': 5, '1,T': 3, 'C,G': 1, '0,D': 26, '0,C': 10, '2,Z': 1, '1,G': 2, '6,S': 2}\n",
    "{'J,T': 9, '7,Z': 1, '5,9': 4, '3,8': 3, 'A,K': 7, '0,Q': 8, '1,7': 6, 'C,G': 1, '5,6': 5, '8,B': 13, '0,G': 2, '6,8': 7, '4,A': 7, '0,D': 23, '0,C': 10, 'G,Q': 1, '3,5': 1, 'B,D': 1, 'X,Y': 5, '9,B': 4, '5,8': 5}\n",
    "{'1,7': 1, '1,3': 1, '6,8': 11, 'P,R': 2, '5,6': 11, 'G,Q': 4, 'K,Y': 1, '9,S': 7, '7,T': 2, '8,B': 71, '5,K': 7, '4,A': 3, '5,F': 2, '3,B': 2, '0,Q': 9, '1,Y': 11, '1,T': 20, '6,B': 6, '6,G': 2, 'D,Q': 2, '0,D': 53, '0,C': 3, '2,Z': 7}\n",
    "{'J,T': 2, 'C,G': 4, '7,T': 5, '0,Q': 13, '0,1': 2, '5,S': 4, '1,T': 3, '9,S': 6, '5,6': 15, '1,3': 2, '8,B': 13, '9,D': 1, '0,D': 14, '0,C': 1, '4,G': 1, '6,S': 2, '1,C': 1, '4,L': 1}\n",
    "{'J,T': 2, '0,U': 5, '3,8': 3, '9,S': 2, '0,Q': 4, '7,T': 1, '1,T': 14, '5,6': 19, '8,B': 49, '6,8': 8, '4,A': 4, '0,D': 24, '9,B': 2, '2,Z': 3, '6,S': 2, '3,B': 6}\n",
    "{'F,Y': 1, 'D,Q': 1, '6,K': 1, '7,T': 1, '6,E': 3, '0,Q': 9, '5,S': 3, '1,T': 3, '1,7': 1, '5,6': 10, '8,B': 27, '4,A': 1, '0,D': 61, '0,C': 25, 'G,Q': 1, '2,Z': 22, '5,B': 5, '3,8': 5, '1,4': 2, '3,B': 1, '9,S': 6}\n",
    "{'4,7': 1, '9,S': 1, '0,Q': 5, '5,6': 5, '1,T': 7, 'C,G': 2, '7,T': 15, '8,B': 5, '6,8': 2, '0,D': 22, '0,C': 6, '4,Z': 2, 'G,Q': 3, 'C,Q': 2, '3,B': 2}\n",
    "{'J,T': 2, '1,7': 6, '6,8': 1, '2,3': 1, '5,8': 6, '3,8': 5, '5,6': 109, '4,W': 1, '8,B': 56, '3,S': 5, '4,A': 15, '9,B': 2, '8,S': 29, '3,B': 7, '0,Q': 10, '1,T': 3, '6,E': 12, '0,D': 33, '0,C': 9, '2,Z': 2, '1,G': 4, '6,S': 2, 'C,Q': 2}\n",
    "{'D,Q': 1, '0,3': 2, 'X,Y': 1, '5,S': 6, '1,7': 7, '1,T': 16, '5,6': 14, '8,B': 35, 'F,P': 1, '6,8': 2, '4,A': 1, '0,D': 10, '0,C': 2, 'B,H': 2, 'G,Q': 1, '2,Z': 3, '5,B': 1, 'A,W': 2, '1,4': 1}\n",
    "{'J,T': 4, '0,4': 1, '1,7': 2, '6,8': 10, '3,8': 4, '3,9': 1, 'F,P': 5, 'M,N': 5, '1,J': 3, 'M,X': 2, 'K,X': 3, '9,S': 8, '7,T': 2, '8,B': 9, '9,B': 1, '3,B': 2, '5,6': 3, '0,Q': 8, '1,T': 2, '0,G': 1, '0,D': 22, '0,C': 3}\n",
    "{'J,T': 2, '0,1': 2, '1,7': 4, '3,8': 1, '3,9': 1, '5,6': 2, 'D,P': 7, '9,S': 4, '8,B': 71, '5,T': 4, '4,A': 14, '9,B': 2, '4,F': 1, 'C,L': 3, '0,Q': 1, '1,Y': 1, '1,T': 23, '6,E': 6, '1,C': 2, '0,G': 2, 'D,Q': 1, '0,D': 56, '0,C': 6, '2,Z': 2, '1,F': 2, 'C,Q': 3}\n",
    "{'7,T': 3, '0,2': 2, '0,Q': 13, '6,E': 1, '1,T': 21, 'C,G': 2, '5,6': 5, '8,B': 14, 'L,U': 3, 'D,Q': 1, '0,D': 4, '0,C': 23, 'X,Y': 1, '2,Z': 19, 'G,Q': 4, '9,S': 4, '3,B': 2, '4,6': 1}\n",
    "{'J,T': 5, '0,4': 1, '6,8': 9, '9,S': 12, '5,9': 2, '3,8': 2, 'F,P': 2, '5,6': 10, 'G,Q': 1, '3,Y': 1, '8,E': 3, '7,T': 28, '8,B': 25, '9,D': 2, '3,E': 1, '0,Q': 4, '1,T': 20, 'C,G': 1, '6,E': 1, '4,A': 7, '0,D': 60, '0,C': 8, '2,Z': 12, 'B,E': 2}\n",
    "{'7,T': 5, '3,9': 3, '0,Q': 3, '5,S': 4, '1,T': 3, '6,B': 2, '5,6': 6, '8,B': 9, '6,8': 1, '4,A': 3, '0,D': 33, '4,G': 1, '2,Z': 19, '5,B': 3, 'G,Q': 1, 'K,X': 2, 'K,Y': 1}'''\n",
    "print(s)\n",
    "\n",
    "# 收集 混淆集 集合\n",
    "key_set = []\n",
    "for item in s.split('\\n'):\n",
    "    a = eval(item)\n",
    "    key_set += a.keys()\n",
    "\n",
    "key_set = sorted(set(key_set))\n",
    "print(key_set)\n",
    "\n",
    "result = [] \n",
    "for item in s.split('\\n'):\n",
    "    a = eval(item)\n",
    "    for i in key_set:\n",
    "        if i not in a.keys():\n",
    "            a[i]=0 \n",
    "#     print(a)\n",
    "    \n",
    "    print([item[1] for item in sorted(a.items(),key = lambda x:x[0])])\n",
    "    \n",
    "    result.append(sorted(a.items(),key = lambda x:x[0]))\n",
    "#     break\n",
    "\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 保存34分类TOP21的应用集预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 34分类前21个模型的预测结果\n",
    "predict_result_34class_file = open(os.path.join(model_root_path,'34class_o1_predict_result_e5.pkl'),'w')\n",
    "\n",
    "run_id = [99,129,141,245,249,270,287,300,311,375,425,509,543,630,758,864,875,890,905,975,1014]\n",
    "# run_id = [875,890,905,975,1014]\n",
    "run_idx = 0\n",
    "with open(os.path.join(model_root_path, '34class_model_weight.pkl'), 'r') as fin:\n",
    "    for index in range(1, len(model_file_list_path) + 1):\n",
    "        # 从 模型1 开始，依次往后\n",
    "        # 找到对应模型文件\n",
    "#         if index != run_id[run_idx]:\n",
    "#             weights = pickle.load(fin)\n",
    "#             continue\n",
    "        \n",
    "        if index < run_id[run_idx]:\n",
    "            weights = pickle.load(fin)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        weights = pickle.load(fin)\n",
    "\n",
    "        # print('OK')\n",
    "        int_predict,(test_accuracy, graterThan2, graterThan5, graterThan10,badcase) = \\\n",
    "                                            cnn_batch_predict_spark(X_other_rdd,y_other, weights)\n",
    "        \n",
    "        print(index,test_accuracy, graterThan2, graterThan5,graterThan10)\n",
    "        print(badcase)\n",
    "        \n",
    "        pickle.dump(np.asarray(int_predict),\n",
    "                    predict_result_34class_file\n",
    "                   )\n",
    "\n",
    "        \n",
    "#         print(test_accuracy, graterThan5, graterThan10)\n",
    "        run_idx += 1\n",
    "        if run_idx>=len(run_id):\n",
    "            break\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存34分类TOP21的 测试集/应用集 预测结果（用5-6二分类器修正）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-90fa6780faab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"option = 'test'\\n# option = 'other'\\n\\nif option == 'test':\\n    predict_result_34class_file = open(os.path.join(model_root_path, '34class_test_predict_result_e5.pkl'), 'r')\\n    X = X_test\\n    y = np.asarray(y_test)\\nelif option == 'other':\\n    predict_result_34class_file = open(os.path.join(model_root_path, '34class_other_predict_result_e5.pkl'), 'r')\\n    X = X_other\\n    y = y_other\\n\\n# run_id = [99, 129, 141, 245, 249, 270, 287, 300, 311, 375, 425, 509, 543, 630, 758, 864, 875, 890, 905, 975, 1014]\\nrun_id = [129, 141, 245, 249, 270, 287, 300, 311, 375, 425, 509, 543, 630, 758, 864, 875, 890, 905, 975, 1014]\\ncou = 0\\nfor index in run_id:\\n    \\n    int_predict_34class = np.asarray(pickle.load(predict_result_34class_file))\\n    \\n    if int_predict_34class is None:\\n        break\\n    \\n    # \\u8bfb\\u53d6\\u4e8c\\u5206\\u7c7b\\u5668\\u7684\\u6743\\u91cd\\n    weights = pickle.load(open(os.path.join(model_root_path, '56binary_model_weight.pkl'), 'r'))\\n    # \\u88ab\\u9884\\u6d4b\\u621056\\u7684\\u6570\\u636e\\n    idx_predicted_56 = (int_predict_34class == 5) + (int_predict_34class == 6)\\n    print('\\u9884\\u6d4b\\u62105-6\\u7684\\u4e2a\\u6570:%d' % sum(idx_predicted_56))\\n\\n    \\n#     X_rdd = sc.parallelize(X[idx_predicted_56])\\n#     X_rdd.cache()\\n    \\n#     yy = y[idx_predicted_56]\\n    \\n#     X_rdd.count()\\n#     break\\n#     binary_result,(test_accuracy, graterThan2, graterThan5, graterThan10,badcase)= cnn_batch_predict_spark(\\n#         X_rdd, \\n#         y[idx_predicted_56],\\n#         weights\\n#     )\\n    \\n# #     print(index, test_accuracy)\\n# #     print(binary_result)\\n# #     break\\n#     binary_result[binary_result == 0] = 5\\n#     binary_result[binary_result == 1] = 6\\n    \\n    # \\u4fee\\u6b63\\u7ed3\\u679c\\n    int_predict_34class[idx_predicted_56] = binary_result\\n    print(index, count_result(int_predict_34class, y))\\n    \\n    break\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_eof\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_eof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_eof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/usr/lib/python2.7/pickle.py\u001b[0m(880)\u001b[0;36mload_eof\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    878 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    879 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mload_eof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 880 \u001b[0;31m        \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    881 \u001b[0;31m    \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_eof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    882 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "option = 'test'\n",
    "# option = 'other'\n",
    "\n",
    "if option == 'test':\n",
    "    predict_result_34class_file = open(os.path.join(model_root_path, '34class_test_predict_result_e5.pkl'), 'r')\n",
    "    X = X_test\n",
    "    y = np.asarray(y_test)\n",
    "elif option == 'other':\n",
    "    predict_result_34class_file = open(os.path.join(model_root_path, '34class_other_predict_result_e5.pkl'), 'r')\n",
    "    X = X_other\n",
    "    y = y_other\n",
    "\n",
    "run_id = [99, 129, 141, 245, 249, 270, 287, 300, 311, 375, 425, 509, 543, 630, 758, 864, 875, 890, 905, 975, 1014]\n",
    "# run_id = [129, 141, 245, 249, 270, 287, 300, 311, 375, 425, 509, 543, 630, 758, 864, 875, 890, 905, 975, 1014]\n",
    "cou = 0\n",
    "for index in run_id:\n",
    "    try:\n",
    "        int_predict_34class = np.asarray(pickle.load(predict_result_34class_file))\n",
    "    \n",
    "    \n",
    "        # 读取二分类器的权重\n",
    "        weights = pickle.load(open(os.path.join(model_root_path, '56binary_model_weight.pkl'), 'r'))\n",
    "        # 被预测成56的数据\n",
    "        idx_predicted_56 = (int_predict_34class == 5) + (int_predict_34class == 6)\n",
    "        print('预测成5-6的个数:%d' % sum(idx_predicted_56))\n",
    "\n",
    "\n",
    "    #     X_rdd = sc.parallelize(X[idx_predicted_56])\n",
    "    #     X_rdd.cache()\n",
    "\n",
    "    #     yy = y[idx_predicted_56]\n",
    "\n",
    "    #     X_rdd.count()\n",
    "    #     break\n",
    "    #     binary_result,(test_accuracy, graterThan2, graterThan5, graterThan10,badcase)= cnn_batch_predict_spark(\n",
    "    #         X_rdd, \n",
    "    #         y[idx_predicted_56],\n",
    "    #         weights\n",
    "    #     )\n",
    "\n",
    "    # #     print(index, test_accuracy)\n",
    "    # #     print(binary_result)\n",
    "    # #     break\n",
    "        print(binary_result ==0)\n",
    "        binary_result = np.asarray(binary_result)\n",
    "    #     binary_result[binary_result == 0] = 5\n",
    "    #     binary_result[binary_result == 1] = 6\n",
    "\n",
    "        # 修正结果\n",
    "        int_predict_34class[idx_predicted_56] = binary_result\n",
    "        print(index, count_result(int_predict_34class, y))\n",
    "\n",
    "        break\n",
    "        \n",
    "    except:\n",
    "        print('end!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
