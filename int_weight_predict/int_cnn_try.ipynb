{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 尝试写一个整形权重CNN的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb 1\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)  # for reproducibility\n",
    "nb_classes = 34\n",
    "nb_epoch = 30\n",
    "batch_size = 128\n",
    "\n",
    "image_higth, image_width = 15, 15\n",
    "# lr = [0.05, 0.01, 0.005]\n",
    "layer1 = 10\n",
    "hidden1 = 40\n",
    "region = 3\n",
    "\n",
    "# 模型权重根目录\n",
    "model_root_path = '/home/jdwang/PycharmProjects/digitRecognition/int_weight_predict/modelAndData1122/'\n",
    "model_file_list_path = os.listdir(os.path.join(model_root_path, 'model'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义必要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_valdata(version='1122'):\n",
    "    \"\"\"读取不同版本的测试集\n",
    "    1120 - 对应 /home/jdwang/PycharmProjects/digitRecognition/int_weight_predict/modelAndData1120/Data/\n",
    "    1122 - 对应 /home/jdwang/PycharmProjects/digitRecognition/int_weight_predict/modelAndData1122/Data/\n",
    "\n",
    "    :param dir_path: str\n",
    "    :param version: str\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # 数据集根目录\n",
    "    data_root_path = '/home/jdwang/PycharmProjects/digitRecognition/int_weight_predict/'\n",
    "\n",
    "    # 读取验证数据、测试数据\n",
    "    if version == '1122':\n",
    "        val_file_path = os.path.join(data_root_path, 'modelAndData1122/Data/', 'TrainSet_trainAndVal_testSet.pickle')\n",
    "        other_file_path = os.path.join(data_root_path, 'modelAndData1122/Data/', 'Olddata_TestSet.pickle')\n",
    "        with open(val_file_path, 'rb') as train_file:\n",
    "            train_X = pickle.load(train_file)\n",
    "            train_y = pickle.load(train_file)\n",
    "            val_X, val_y = None, None\n",
    "            test_X = pickle.load(train_file)\n",
    "            test_y = pickle.load(train_file)\n",
    "    elif version == '1120':\n",
    "        val_file_path = os.path.join(data_root_path, 'modelAndData1120/Data/', 'valSet&TestSet.pickle')\n",
    "        other_file_path = os.path.join(data_root_path, 'modelAndData1120/Data/', 'Olddata_TestSet.pickle')\n",
    "        with open(val_file_path, 'rb') as train_file:\n",
    "            val_X = pickle.load(train_file)\n",
    "            val_y = pickle.load(train_file)\n",
    "            test_X = pickle.load(train_file)\n",
    "            test_y = pickle.load(train_file)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    with open(other_file_path, 'rb') as otherFile:\n",
    "        other_X = pickle.load(otherFile)\n",
    "        other_y = pickle.load(otherFile)\n",
    "\n",
    "    return (val_X, val_y), (test_X, test_y), (other_X, other_y)\n",
    "\n",
    "\n",
    "def Net_model(layer1, hidden1, region, rows, cols, nb_classes, lr=0.01, decay=1e-6, momentum=0.9):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "    from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "    from keras.optimizers import SGD\n",
    "    from keras import backend as K\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(layer1, region, region,\n",
    "                            border_mode='valid',\n",
    "                            input_shape=(1, rows, cols)))\n",
    "\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())  # 平铺\n",
    "\n",
    "    model.add(Dense(hidden1))  # Full connection 1:  1000\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # 获取CNN的中间结果\n",
    "    mid_output = K.function(inputs=[\n",
    "        model.layers[0].input,\n",
    "        K.learning_phase(),\n",
    "    ],\n",
    "        outputs=[\n",
    "            model.layers[-9].output,\n",
    "            model.layers[-8].output,\n",
    "            model.layers[-7].output,\n",
    "            model.layers[-6].output,\n",
    "            model.layers[-5].output,\n",
    "            model.layers[-4].output,\n",
    "            model.layers[-3].output,\n",
    "            model.layers[-2].output,\n",
    "            model.layers[-1].output,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sgd = SGD(lr=lr, decay=decay, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model, mid_output\n",
    "\n",
    "\n",
    "def test_model(model_file, X_test, Y_test):\n",
    "    # 加载模型架构\n",
    "    # 这里的 lr 设置什么不影响\n",
    "    model, mid_output = Net_model(layer1, hidden1, region, image_higth, image_width, nb_classes=34, lr=0)\n",
    "    model.load_weights(model_file)\n",
    "\n",
    "    # 预测\n",
    "    predicted = model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "    return count_result(predicted, Y_test)\n",
    "\n",
    "\n",
    "def count_result(predicted, Y_test):\n",
    "    '''统计预测情况，包括混淆集个数等\n",
    "\n",
    "    :return:\n",
    "    '''\n",
    "    # 统计混淆集\n",
    "    badcase = {}\n",
    "    for i in range(0, len(Y_test)):\n",
    "        if (tramsform(predicted[i]) in ['1', 'I'] and tramsform(Y_test[i]) in ['1', 'I']):\n",
    "            # 1跟I区分，只要 是 测试 成1或I，而实际值是 1或I都算对\n",
    "            predicted[i] = Y_test[i]\n",
    "        if predicted[i] != Y_test[i]:\n",
    "            ch1 = tramsform(Y_test[i])\n",
    "            ch2 = tramsform(predicted[i])\n",
    "            string = ','.join(sorted([ch1, ch2]))\n",
    "\n",
    "            if badcase.has_key(string):\n",
    "                badcase[string] += 1\n",
    "            else:\n",
    "                badcase[string] = 1\n",
    "\n",
    "    # 计算测试准确率\n",
    "    test_accuracy = np.mean(np.equal(predicted, Y_test))\n",
    "    graterThan5 = 0\n",
    "    graterThan10 = 0\n",
    "    for key, value in badcase.items():\n",
    "        if value >= 5:\n",
    "            graterThan5 += 1\n",
    "        if value >= 10:\n",
    "            graterThan10 += 1\n",
    "\n",
    "    return (test_accuracy, graterThan5, graterThan10)\n",
    "\n",
    "\n",
    "def tramsform(num):\n",
    "    \"\"\" 数字 转换成 字符\n",
    "\n",
    "    :param num:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if num < 10:\n",
    "        return str(num)\n",
    "    else:\n",
    "        if num >= 24:\n",
    "            num += 1\n",
    "        if num >= 31:\n",
    "            num += 1\n",
    "        return chr(ord('A') + num - 10)\n",
    "\n",
    "\n",
    "def conv_pool_operation(img, conv_W, conv_b):\n",
    "    \"\"\"CNN 卷积 和 池化操作\n",
    "        一张图片\n",
    "    :param img: array-3D\n",
    "        一张图片，3D，(num_of_channels,img_height,img_width)\n",
    "    :param conv_W: array-4D\n",
    "        10*3*3\n",
    "    :param conv_b:\n",
    "    :return: array-3D\n",
    "    \"\"\"\n",
    "    filter_row, filter_col = conv_W.shape[2:]\n",
    "    img_row, img_col = img.shape[1:]\n",
    "    # convolution\n",
    "    # 3D\n",
    "    conv_result = np.zeros((conv_W.shape[0], img_row - filter_row + 1, img_col - filter_col + 1))\n",
    "    # quit()\n",
    "    for filter_index in range(conv_W.shape[0]):\n",
    "        for x in range(0, img_row - filter_row + 1):\n",
    "            for y in range(0, img_col - filter_col + 1):\n",
    "                i = img[0, x:x + filter_row, y:y + filter_col].flatten()\n",
    "                j = conv_W[filter_index, 0].flatten()[-1::-1]\n",
    "                conv_result[filter_index,\n",
    "                            x,\n",
    "                            y] = tanh_approximate_function(np.dot(i, j) + conv_b[filter_index])\n",
    "                # print(np.dot(i, j) + conv_b[filter_index])\n",
    "\n",
    "    # conv_result = tanh_approximate_function(conv_result)\n",
    "    pool_row, pool_col = 2, 2\n",
    "    pool_result = np.zeros(\n",
    "        (conv_result.shape[0], conv_result.shape[1] / pool_row, conv_result.shape[2] / pool_col))\n",
    "    # max-pooling\n",
    "    for channel_index in range(pool_result.shape[0]):\n",
    "        for x in range(pool_result.shape[1]):\n",
    "            for y in range(pool_result.shape[2]):\n",
    "                pool_result[\n",
    "                    channel_index,\n",
    "                    x,\n",
    "                    y\n",
    "                ] = np.max(\n",
    "                    conv_result[\n",
    "                    channel_index,\n",
    "                    x * pool_row: (x + 1) * pool_row,\n",
    "                    y * pool_col: (y + 1) * pool_col\n",
    "                    ])\n",
    "    return pool_result\n",
    "\n",
    "\n",
    "def hidden_operation(feature_vector, W, b, activion='tanh'):\n",
    "    \"\"\" 隐含层操作\n",
    "\n",
    "    :param activion: str\n",
    "        激活函数\n",
    "    :param feature_vector: array-like\n",
    "        一张 图片的 feature vector，1D\n",
    "    :param W: array-2D\n",
    "        权重\n",
    "    :param b: array-1D\n",
    "        偏差\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    temp = np.dot(feature_vector, W) + b\n",
    "    if activion == 'tanh':\n",
    "        return np.asarray([tanh_approximate_function(item) for item in temp])\n",
    "    elif activion == 'none':\n",
    "        return temp\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def tanh_approximate_function(x):\n",
    "    \"\"\"\n",
    "         * tanh x=sinh x / cosh x\n",
    "         * 其中sinh x=(e^(x)-e^(-x))/2 ，cosh x=(e^x+e^(-x))/2\n",
    "         * 所以tanhx = (e^(x)-e^(-x)) /(e^x+e^(-x))\n",
    "    \"\"\"\n",
    "    #     return (int)(tanh(x));\n",
    "\n",
    "    if x > 10:\n",
    "        return 1\n",
    "    elif x < -10:\n",
    "        return -1\n",
    "    else:\n",
    "        return (int)((np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x)))\n",
    "\n",
    "\n",
    "def cnn_batch_predict(X_val, weights):\n",
    "    '''CNN批量预测\n",
    "\n",
    "    :param X_val:\n",
    "    :param weights:\n",
    "    :return:\n",
    "    '''\n",
    "    weights = [(item * 1e6).astype(dtype=int) for item in weights]\n",
    "    # result = cnn_predict(X_val[0],weights)\n",
    "    result = []\n",
    "    for index, img in enumerate(X_val):\n",
    "        if (index + 1) % 1000 == 0:\n",
    "            print('%d' % (index + 1))\n",
    "        result.append(cnn_predict(img, weights))\n",
    "    return np.asarray(result)\n",
    "\n",
    "\n",
    "def cnn_predict(img, weights):\n",
    "    '''单张图片的预测\n",
    "\n",
    "    :param img:\n",
    "    :param weights:\n",
    "    :return:\n",
    "    '''\n",
    "    # 3D\n",
    "    imgs_conv_result = conv_pool_operation(img, weights[0], weights[1])\n",
    "    # print('conv over..')\n",
    "    flatten_result = imgs_conv_result.flatten()\n",
    "    # print('flatten over..')\n",
    "    # print(flatten_result.shape)\n",
    "    hidden1_output = hidden_operation(flatten_result, weights[2], weights[3], activion='tanh')\n",
    "\n",
    "    # print('hidden1 over..')\n",
    "    hidden2_output = hidden_operation(hidden1_output, weights[4], weights[5], activion='none')\n",
    "    # print('hidden2 over..')\n",
    "    # print(hidden2_output.shape)\n",
    "    result = np.argmax(hidden2_output)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def cnn_batch_predict_spark(X_val_rdd,y_val, weights):\n",
    "    weights = [(item * 1e6).astype(dtype=int) for item in weights]\n",
    "#     result_rdd = X_val_rdd.map(lambda x:cnn_predict(x,weights))\n",
    "    \n",
    "    result_rdd = X_val_rdd.map(lambda x:conv_pool_operation(x, weights[0], weights[1]))\n",
    "    result_rdd = result_rdd.map(lambda x: x.flatten())\n",
    "    result_rdd = result_rdd.map(lambda x:hidden_operation(x,weights[2], weights[3],activion='tanh'))\n",
    "    result_rdd = result_rdd.map(lambda x:hidden_operation(x,weights[4], weights[5],activion='none'))\n",
    "    result_rdd = result_rdd.map(np.argmax)\n",
    "    \n",
    "#     result_rdd.cache()\n",
    "    result = result_rdd.collect()\n",
    "    accu = np.mean(np.asarray(result) == y_val) \n",
    "#     print(accu)\n",
    "    return count_result(result,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64381, 1, 15, 15)\n",
      "(243391, 1, 15, 15)\n",
      "CPU times: user 4 s, sys: 300 ms, total: 4.3 s\n",
      "Wall time: 4.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# region 读取数据集：验证数据(64369个)、测试数据(64381个)、其他应用数据集(243391个)\n",
    "(X_val, y_val), (X_test, y_test), (X_other, y_other) = load_valdata(version='1122')\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_other.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将图片数据序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 16 ms, total: 28 ms\n",
      "Wall time: 366 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_val_rdd = sc.parallelize(X_test)\n",
    "y_val = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.06 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method RDD.cache of ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:475>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_val_rdd.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# X_val_rdd.count()\n",
    "# len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with open(os.path.join(model_root_path, 'model_weight.pkl'), 'r') as fin:\n",
    "    for index in range(1, len(model_file_list_path) + 1):\n",
    "        # 从 模型1 开始，依次往后\n",
    "        # 找到对应模型文件\n",
    "\n",
    "        weights = pickle.load(fin)\n",
    "\n",
    "        # print('OK')\n",
    "        print(index,cnn_batch_predict_spark(X_val_rdd,y_val, weights))\n",
    "#         print(test_accuracy, graterThan5, graterThan10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.81 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.96 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.81 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 4.05 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.81 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 4.05 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.01 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.96 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.01 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.96 µs\n",
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 4.54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for i in range(10):\n",
    "    %time pass\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
