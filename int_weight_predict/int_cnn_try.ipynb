{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 尝试写一个整形权重CNN的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%pdb 1\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import struct\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)  # for reproducibility\n",
    "nb_classes = 34\n",
    "nb_epoch = 30\n",
    "batch_size = 128\n",
    "\n",
    "image_higth, image_width = 15, 15\n",
    "# lr = [0.05, 0.01, 0.005]\n",
    "layer1 = 10\n",
    "hidden1 = 40\n",
    "region = 3\n",
    "# 数据集根目录\n",
    "data_root_path = '/home/jdwang/PycharmProjects/digitRecognition/int_weight_predict/modelAndData/Data/'\n",
    "# 模型权重根目录\n",
    "model_root_path = '/home/jdwang/PycharmProjects/digitRecognition/int_weight_predict/modelAndData/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义必要的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_valdata(dir_path):\n",
    "    # 读取验证数据、测试数据\n",
    "    with open(os.path.join(dir_path, 'valSet&TestSet.pickle'), 'rb') as train_file:\n",
    "        val_X = pickle.load(train_file)\n",
    "        val_y = pickle.load(train_file)\n",
    "        test_X = pickle.load(train_file)\n",
    "        test_y = pickle.load(train_file)\n",
    "\n",
    "    with open(os.path.join(dir_path, 'Olddata_TestSet.pickle'), 'rb') as otherFile:\n",
    "        other_X = pickle.load(otherFile)\n",
    "        other_y = pickle.load(otherFile)\n",
    "\n",
    "    return (val_X, val_y), (test_X, test_y), (other_X, other_y)\n",
    "\n",
    "\n",
    "def Net_model(layer1, hidden1, region, rows, cols, nb_classes, lr=0.01, decay=1e-6, momentum=0.9):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(layer1, region, region,\n",
    "                            border_mode='valid',\n",
    "                            input_shape=(1, rows, cols)))\n",
    "\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())  # 平铺\n",
    "\n",
    "    model.add(Dense(hidden1))  # Full connection 1:  1000\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # 获取CNN的中间结果\n",
    "    mid_output = K.function(inputs=[\n",
    "        model.layers[0].input,\n",
    "        K.learning_phase(),\n",
    "    ],\n",
    "        outputs=[\n",
    "            model.layers[-9].output,\n",
    "            model.layers[-8].output,\n",
    "            model.layers[-7].output,\n",
    "            model.layers[-6].output,\n",
    "            model.layers[-5].output,\n",
    "            model.layers[-4].output,\n",
    "            model.layers[-3].output,\n",
    "            model.layers[-2].output,\n",
    "            model.layers[-1].output,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sgd = SGD(lr=lr, decay=decay, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model, mid_output\n",
    "\n",
    "\n",
    "def test_model(model, X_test, Y_test):\n",
    "    # 预测\n",
    "    predicted = model.predict_classes(X_test, verbose=0)\n",
    "    \n",
    "    return get_result(predicted,Y_test)\n",
    "    \n",
    "def get_result(predicted,Y_test):\n",
    "    # 获得统计结果\n",
    "    # 统计混淆集\n",
    "    badcase = {}\n",
    "    for i in range(0, len(Y_test)):\n",
    "        if (tramsform(predicted[i]) in ['1', 'I'] and tramsform(Y_test[i]) in ['1', 'I']):\n",
    "            # 1跟I区分，只要 是 测试 成1或I，而实际值是 1或I都算对\n",
    "            predicted[i] = Y_test[i]\n",
    "        if predicted[i] != Y_test[i]:\n",
    "            ch1 = tramsform(Y_test[i])\n",
    "            ch2 = tramsform(predicted[i])\n",
    "            string = ','.join([ch1, ch2])\n",
    "\n",
    "            if badcase.has_key(string):\n",
    "                badcase[string] += 1\n",
    "            else:\n",
    "                badcase[string] = 1\n",
    "\n",
    "    # 计算测试准确率\n",
    "    test_accuracy = np.mean(np.equal(predicted, Y_test))\n",
    "    graterThan5 = 0\n",
    "    graterThan10 = 0\n",
    "    for key, value in badcase.items():\n",
    "        if value >= 5:\n",
    "            graterThan5 += 1\n",
    "        if value >= 10:\n",
    "            graterThan10 += 1\n",
    "\n",
    "    return (test_accuracy, graterThan5, graterThan10)\n",
    "\n",
    "\n",
    "def tramsform(num):\n",
    "    \"\"\" 数字 转换成 字符\n",
    "\n",
    "    :param num:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if num < 10:\n",
    "        return str(num)\n",
    "    else:\n",
    "        if num >= 24:\n",
    "            num += 1\n",
    "        if num >= 31:\n",
    "            num += 1\n",
    "        return chr(ord('A') + num - 10)\n",
    "\n",
    "\n",
    "def conv_pool_operation(img, conv_W, conv_b):\n",
    "    \"\"\"CNN 卷积 和 池化操作\n",
    "        一张图片\n",
    "    :param img: array-3D\n",
    "        一张图片，3D，(num_of_channels,img_height,img_width)\n",
    "    :param conv_W: array-4D\n",
    "        10*3*3\n",
    "    :param conv_b:\n",
    "    :return: array-3D\n",
    "    \"\"\"\n",
    "    filter_row, filter_col = conv_W.shape[2:]\n",
    "    img_row, img_col = img.shape[1:]\n",
    "    # convolution\n",
    "    # 3D\n",
    "    conv_result = np.zeros((conv_W.shape[0], img_row - filter_row + 1, img_col - filter_col + 1))\n",
    "    # quit()\n",
    "    for filter_index in range(conv_W.shape[0]):\n",
    "        for x in range(0, img_row - filter_row + 1):\n",
    "            for y in range(0, img_col - filter_col + 1):\n",
    "                i = img[0, x:x + filter_row, y:y + filter_col].flatten()\n",
    "                j = conv_W[filter_index, 0].flatten()[-1::-1]\n",
    "                conv_result[filter_index,\n",
    "                            x,\n",
    "                            y] = tanh_approximate_function(np.dot(i, j) + conv_b[filter_index])\n",
    "                # print(np.dot(i, j) + conv_b[filter_index])\n",
    "\n",
    "    # conv_result = tanh_approximate_function(conv_result)\n",
    "    pool_row, pool_col = 2, 2\n",
    "    pool_result = np.zeros(\n",
    "        (conv_result.shape[0], conv_result.shape[1] / pool_row, conv_result.shape[2] / pool_col))\n",
    "    # max-pooling\n",
    "    for channel_index in range(pool_result.shape[0]):\n",
    "        for x in range(pool_result.shape[1]):\n",
    "            for y in range(pool_result.shape[2]):\n",
    "                pool_result[\n",
    "                    channel_index,\n",
    "                    x,\n",
    "                    y\n",
    "                ] = np.max(\n",
    "                    conv_result[\n",
    "                    channel_index,\n",
    "                    x * pool_row: (x + 1) * pool_row,\n",
    "                    y * pool_col: (y + 1) * pool_col\n",
    "                    ])\n",
    "    return pool_result\n",
    "\n",
    "\n",
    "\n",
    "def hidden_operation(feature_vector, W, b,activion='tanh'):\n",
    "    \"\"\" 隐含层操作\n",
    "\n",
    "    :param activion: str\n",
    "        激活函数\n",
    "    :param feature_vector: array-like\n",
    "        一张 图片的 feature vector，1D\n",
    "    :param W: array-2D\n",
    "        权重\n",
    "    :param b: array-1D\n",
    "        偏差\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    temp = np.dot(feature_vector, W) + b\n",
    "    if activion=='tanh':\n",
    "        return np.asarray([tanh_approximate_function(item) for item in temp])\n",
    "    elif activion=='none':\n",
    "        return temp\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def tanh_approximate_function(x):\n",
    "    \"\"\"\n",
    "         * tanh x=sinh x / cosh x\n",
    "         * 其中sinh x=(e^(x)-e^(-x))/2 ，cosh x=(e^x+e^(-x))/2\n",
    "         * 所以tanhx = (e^(x)-e^(-x)) /(e^x+e^(-x))\n",
    "    \"\"\"\n",
    "    #     return (int)(tanh(x));\n",
    "\n",
    "    if x > 10:\n",
    "        return 1\n",
    "    elif x < -10:\n",
    "        return -1\n",
    "    else:\n",
    "        return (int)((np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x)))\n",
    "\n",
    "\n",
    "def cnn_batch_predict(X_val, weights):\n",
    "    '''CNN批量预测\n",
    "\n",
    "    :param X_val:\n",
    "    :param weights:\n",
    "    :return:\n",
    "    '''\n",
    "    weights = [(item * 1e6).astype(dtype=int) for item in weights]\n",
    "    # result = cnn_predict(X_val[0],weights)\n",
    "    result = []\n",
    "    for index,img in enumerate(X_val):\n",
    "        if (index+1)%1000 ==0:\n",
    "            print('%d'%(index+1))\n",
    "        result.append( cnn_predict(img,weights))\n",
    "    return np.asarray(result)\n",
    "\n",
    "\n",
    "\n",
    "def cnn_predict(img, weights):\n",
    "    '''单张图片的预测\n",
    "\n",
    "    :param img:\n",
    "    :param weights:\n",
    "    :return:\n",
    "    '''\n",
    "    # 3D\n",
    "    imgs_conv_result = conv_pool_operation(img, weights[0], weights[1])\n",
    "    # print('conv over..')\n",
    "    flatten_result = imgs_conv_result.flatten()\n",
    "    # print('flatten over..')\n",
    "    # print(flatten_result.shape)\n",
    "    hidden1_output = hidden_operation(flatten_result, weights[2], weights[3],activion='tanh')\n",
    "\n",
    "    # print('hidden1 over..')\n",
    "    hidden2_output = hidden_operation(hidden1_output, weights[4], weights[5],activion='none')\n",
    "    # print('hidden2 over..')\n",
    "    # print(hidden2_output.shape)\n",
    "    result = np.argmax(hidden2_output)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cnn_batch_predict_spark(X_val_rdd,y_val, weights):\n",
    "    weights = [(item * 1e6).astype(dtype=int) for item in weights]\n",
    "    result_rdd = X_val_rdd.map(lambda x:cnn_predict(x,weights))\n",
    "    result_rdd.cache()\n",
    "    result = result_rdd.collect()\n",
    "#     accu = np.mean(np.asarray(result) == y_val) \n",
    "#     print(accu)\n",
    "    return get_result(result,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.65 s, sys: 156 ms, total: 3.81 s\n",
      "Wall time: 3.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# region 读取数据集：验证数据(64369个)、测试数据(64381个)、其他应用数据集(243391个)\n",
    "(X_val, y_val), (X_test, y_test), (X_other, y_other) = load_valdata(data_root_path)\n",
    "model_file_list_path = os.listdir(model_root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将图片数据序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 ms, sys: 52 ms, total: 96 ms\n",
      "Wall time: 452 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_val_rdd = sc.parallelize(X_other)\n",
    "y_val = y_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.06 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method RDD.cache of ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:475>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_val_rdd.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 1.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "243391"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# X_val_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for index in range(1, len(model_file_list_path) + 1):\n",
    "    # 从 模型1 开始，依次往后\n",
    "    # 找到对应模型文件\n",
    "#     index = 2261\n",
    "    for item in model_file_list_path:\n",
    "        if item.__contains__('iteration%d_model_weights_10-40_region3_' % index):\n",
    "            model_file = item\n",
    "            break\n",
    "\n",
    "#     print(model_file)\n",
    "\n",
    "    # 加载模型架构\n",
    "    # 这里的 lr 设置什么不影响\n",
    "    model, mid_output = Net_model(layer1, hidden1, region, image_higth, image_width, nb_classes=34, lr=0)\n",
    "    # model.summary()\n",
    "\n",
    "    model.load_weights(os.path.join(model_root_path, model_file))\n",
    "    # mid_result = mid_output([X_val[:1], 0])\n",
    "\n",
    "    # save_cnn_weight_to_bininary_file(model.get_weights())\n",
    "    # predicted = model.predict_classes(X_val, verbose=0)\n",
    "    # print(np.mean(predicted == y_val))\n",
    "    #\n",
    "    # print('OK')\n",
    "    test_accuracy, graterThan5, graterThan10 = cnn_batch_predict_spark(\n",
    "        X_val_rdd,\n",
    "        y_val, \n",
    "        model.get_weights()\n",
    "    )\n",
    "    print(model_file,test_accuracy, graterThan5, graterThan10)\n",
    "#     break\n",
    "    # if (np.mean(int_predict == predicted)) != 1.0:\n",
    "    #     print(index, model_file)\n",
    "    #     print(predicted)\n",
    "    #     print(int_predict)\n",
    "    #     print(np.mean(int_predict == predicted))\n",
    "    #\n",
    "    # # if (index + 1) % 10 == 0:\n",
    "    # #     print(index)\n",
    "    # # assert (np.mean(int_predict == predicted)) == 1.0\n",
    "    #\n",
    "    # (val_accuracy, val5, val10) = test_model(model, X_val, y_val)\n",
    "    # print('验证集：%f,%d,%d' % (val_accuracy, val5, val10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}