/usr/bin/python2.7 /home/jdwang/PycharmProjects/digitRecognition/cnn/cnn_train.py
Using Theano backend.
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
zeropadding2d_1 (ZeroPadding2D)  (None, 1, 17, 17)     0           zeropadding2d_input_1[0][0]
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (None, 32, 15, 15)    320         zeropadding2d_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 32, 15, 15)    0           convolution2d_1[0][0]
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 32, 7, 7)      0           activation_1[0][0]
____________________________________________________________________________________________________
zeropadding2d_2 (ZeroPadding2D)  (None, 32, 9, 9)      0           maxpooling2d_1[0][0]
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 7, 7)      18496       zeropadding2d_2[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 64, 7, 7)      0           convolution2d_2[0][0]
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 64, 3, 3)      0           activation_2[0][0]
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 1, 1)     73856       maxpooling2d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 128, 1, 1)     0           convolution2d_3[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 128)           0           activation_3[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 100)           12900       flatten_1[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)        (None, 100)           0           dense_1[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 100)           0           activation_4[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 50)            5050        dropout_1[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)        (None, 50)            0           dense_2[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 50)            0           activation_5[0][0]
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 34)            1734        dropout_2[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)        (None, 34)            0           dense_3[0][0]
====================================================================================================
Total params: 112356
____________________________________________________________________________________________________
None
Epoch 1/40
3400/3400 [==============================] - 16s - loss: 3.5192 - acc: 0.0438
Epoch 2/40
3400/3400 [==============================] - 16s - loss: 3.3979 - acc: 0.0800
Epoch 3/40
3400/3400 [==============================] - 16s - loss: 3.0158 - acc: 0.1576
Epoch 4/40
3400/3400 [==============================] - 17s - loss: 2.4144 - acc: 0.2968
Epoch 5/40
3400/3400 [==============================] - 16s - loss: 1.8737 - acc: 0.4203
Epoch 6/40
3400/3400 [==============================] - 17s - loss: 1.5233 - acc: 0.5218
Epoch 7/40
3400/3400 [==============================] - 17s - loss: 1.2067 - acc: 0.6035
Epoch 8/40
3400/3400 [==============================] - 17s - loss: 1.0080 - acc: 0.6776
Epoch 9/40
3400/3400 [==============================] - 16s - loss: 0.9016 - acc: 0.7126
Epoch 10/40
3400/3400 [==============================] - 16s - loss: 0.8183 - acc: 0.7365
Epoch 11/40
3400/3400 [==============================] - 16s - loss: 0.7301 - acc: 0.7653
Epoch 12/40
3400/3400 [==============================] - 16s - loss: 0.6821 - acc: 0.7835
Epoch 13/40
3400/3400 [==============================] - 16s - loss: 0.6228 - acc: 0.7994
Epoch 14/40
3400/3400 [==============================] - 16s - loss: 0.5826 - acc: 0.8209
Epoch 15/40
3400/3400 [==============================] - 16s - loss: 0.5235 - acc: 0.8338
Epoch 16/40
3400/3400 [==============================] - 17s - loss: 0.5429 - acc: 0.8306
Epoch 17/40
3400/3400 [==============================] - 17s - loss: 0.4843 - acc: 0.8479
Epoch 18/40
3400/3400 [==============================] - 18s - loss: 0.4764 - acc: 0.8544
Epoch 19/40
3400/3400 [==============================] - 22s - loss: 0.4342 - acc: 0.8644
Epoch 20/40
3400/3400 [==============================] - 19s - loss: 0.4303 - acc: 0.8744
Epoch 21/40
3400/3400 [==============================] - 16s - loss: 0.4066 - acc: 0.8841
Epoch 22/40
3400/3400 [==============================] - 16s - loss: 0.3722 - acc: 0.8829
Epoch 23/40
3400/3400 [==============================] - 17s - loss: 0.3577 - acc: 0.8959
Epoch 24/40
3400/3400 [==============================] - 16s - loss: 0.3577 - acc: 0.8921
Epoch 25/40
3400/3400 [==============================] - 16s - loss: 0.3635 - acc: 0.8918
Epoch 26/40
3400/3400 [==============================] - 17s - loss: 0.3290 - acc: 0.9059
Epoch 27/40
3400/3400 [==============================] - 17s - loss: 0.3366 - acc: 0.9059
Epoch 28/40
3400/3400 [==============================] - 16s - loss: 0.3455 - acc: 0.8979
Epoch 29/40
3400/3400 [==============================] - 16s - loss: 0.3478 - acc: 0.8953
Epoch 30/40
3400/3400 [==============================] - 16s - loss: 0.3269 - acc: 0.9094
Epoch 31/40
3400/3400 [==============================] - 16s - loss: 0.3218 - acc: 0.9071
Epoch 32/40
3400/3400 [==============================] - 17s - loss: 0.2865 - acc: 0.9141
Epoch 33/40
3400/3400 [==============================] - 16s - loss: 0.3045 - acc: 0.9171
Epoch 34/40
3400/3400 [==============================] - 16s - loss: 0.2876 - acc: 0.9138
Epoch 35/40
3400/3400 [==============================] - 16s - loss: 0.2717 - acc: 0.9200
Epoch 36/40
3400/3400 [==============================] - 16s - loss: 0.2622 - acc: 0.9318
Epoch 37/40
3400/3400 [==============================] - 16s - loss: 0.2839 - acc: 0.9209
Epoch 38/40
3400/3400 [==============================] - 16s - loss: 0.2723 - acc: 0.9262
Epoch 39/40
3400/3400 [==============================] - 16s - loss: 0.2758 - acc: 0.9238
Epoch 40/40
3400/3400 [==============================] - 16s - loss: 0.2402 - acc: 0.9341
train time : 686.965172
39104/39104 [==============================] - 69s
[ True  True  True ...,  True  True  True]
2016-07-11 08:18:31,325 : DEBUG : 正确的个数:38398
正确的个数:38398
2016-07-11 08:18:31,496 : DEBUG : 准确率为:0.981946
准确率为:0.981946
2016-07-11 08:18:31,516 : DEBUG : F1为：[ 0.98362334  0.97509013  0.9795382   0.99923739  0.99933066  0.98514668
  0.99884355  0.98882682  0.97992299  0.99900662  0.98783455  0.7184466
  0.98488121  0.86486486  0.99570815  1.          0.99559471  1.
  0.80434783  0.98402556  0.9991357   0.96045198  0.96888889  0.97222222
  0.99413834  0.91169451  0.995671    0.61691542  0.6993007   0.97583548
  0.99646643  0.99130435  0.99799062  0.76626506]
F1为：[ 0.98362334  0.97509013  0.9795382   0.99923739  0.99933066  0.98514668
  0.99884355  0.98882682  0.97992299  0.99900662  0.98783455  0.7184466
  0.98488121  0.86486486  0.99570815  1.          0.99559471  1.
  0.80434783  0.98402556  0.9991357   0.96045198  0.96888889  0.97222222
  0.99413834  0.91169451  0.995671    0.61691542  0.6993007   0.97583548
  0.99646643  0.99130435  0.99799062  0.76626506]
precision:[ 1.          0.99299065  0.99885145  0.99912854  0.99966522  0.99962321
  0.99933884  0.98772321  0.99831886  1.          0.9902439   0.57098765
  0.98417266  0.76574307  0.99145299  1.          1.          1.
  0.68944099  0.97160883  1.          0.92391304  0.99090909  0.94594595
  1.          0.84140969  0.99137931  0.44927536  0.54347826  0.97936017
  1.          0.99563319  0.9959893   0.62598425]
recall_score:[ 0.96777442  0.95782357  0.96095764  0.99934626  0.99899632  0.97108346
  0.99834875  0.98993289  0.96219282  0.99801522  0.98543689  0.96858639
  0.98559078  0.99346405  1.          1.          0.99122807  1.
  0.96521739  0.99676375  0.99827288  1.          0.94782609  1.
  0.98834499  0.99479167  1.          0.98412698  0.98039216  0.97233607
  0.99295775  0.98701299  1.          0.98757764]
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
zeropadding2d_3 (ZeroPadding2D)  (None, 1, 17, 17)     0           zeropadding2d_input_2[0][0]
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 32, 15, 15)    320         zeropadding2d_3[0][0]
____________________________________________________________________________________________________
activation_7 (Activation)        (None, 32, 15, 15)    0           convolution2d_4[0][0]
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 32, 7, 7)      0           activation_7[0][0]
____________________________________________________________________________________________________
zeropadding2d_4 (ZeroPadding2D)  (None, 32, 9, 9)      0           maxpooling2d_3[0][0]
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 64, 7, 7)      18496       zeropadding2d_4[0][0]
____________________________________________________________________________________________________
activation_8 (Activation)        (None, 64, 7, 7)      0           convolution2d_5[0][0]
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 64, 3, 3)      0           activation_8[0][0]
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 128, 1, 1)     73856       maxpooling2d_4[0][0]
____________________________________________________________________________________________________
activation_9 (Activation)        (None, 128, 1, 1)     0           convolution2d_6[0][0]
____________________________________________________________________________________________________
flatten_2 (Flatten)              (None, 128)           0           activation_9[0][0]
____________________________________________________________________________________________________
dense_4 (Dense)                  (None, 100)           12900       flatten_2[0][0]
____________________________________________________________________________________________________
activation_10 (Activation)       (None, 100)           0           dense_4[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 100)           0           activation_10[0][0]
____________________________________________________________________________________________________
dense_5 (Dense)                  (None, 50)            5050        dropout_3[0][0]
____________________________________________________________________________________________________
activation_11 (Activation)       (None, 50)            0           dense_5[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 50)            0           activation_11[0][0]
____________________________________________________________________________________________________
dense_6 (Dense)                  (None, 34)            1734        dropout_4[0][0]
____________________________________________________________________________________________________
activation_12 (Activation)       (None, 34)            0           dense_6[0][0]
====================================================================================================
Total params: 112356
____________________________________________________________________________________________________
None
Epoch 1/40
3400/3400 [==============================] - 16s - loss: 3.5309 - acc: 0.0353
Epoch 2/40
3400/3400 [==============================] - 16s - loss: 3.3852 - acc: 0.0674
Epoch 3/40
3400/3400 [==============================] - 16s - loss: 3.0090 - acc: 0.1529
Epoch 4/40
3400/3400 [==============================] - 16s - loss: 2.4446 - acc: 0.2682
Epoch 5/40
3400/3400 [==============================] - 16s - loss: 1.9373 - acc: 0.3935
Epoch 6/40
3400/3400 [==============================] - 16s - loss: 1.5811 - acc: 0.4929
Epoch 7/40
3400/3400 [==============================] - 16s - loss: 1.2911 - acc: 0.5729
Epoch 8/40
3400/3400 [==============================] - 16s - loss: 1.1123 - acc: 0.6262
Epoch 9/40
3400/3400 [==============================] - 16s - loss: 1.0085 - acc: 0.6694
Epoch 10/40
3400/3400 [==============================] - 16s - loss: 0.8800 - acc: 0.7153
Epoch 11/40
3400/3400 [==============================] - 16s - loss: 0.7721 - acc: 0.7447
Epoch 12/40
3400/3400 [==============================] - 16s - loss: 0.6793 - acc: 0.7844
Epoch 13/40
3400/3400 [==============================] - 16s - loss: 0.7050 - acc: 0.7721
Epoch 14/40
3400/3400 [==============================] - 16s - loss: 0.6363 - acc: 0.7891
Epoch 15/40
3400/3400 [==============================] - 16s - loss: 0.5911 - acc: 0.8062
Epoch 16/40
3400/3400 [==============================] - 16s - loss: 0.5578 - acc: 0.8206
Epoch 17/40
3400/3400 [==============================] - 16s - loss: 0.5126 - acc: 0.8403
Epoch 18/40
3400/3400 [==============================] - 16s - loss: 0.5349 - acc: 0.8312
Epoch 19/40
3400/3400 [==============================] - 16s - loss: 0.5158 - acc: 0.8344
Epoch 20/40
3400/3400 [==============================] - 16s - loss: 0.4962 - acc: 0.8532
Epoch 21/40
3400/3400 [==============================] - 16s - loss: 0.4641 - acc: 0.8588
Epoch 22/40
3400/3400 [==============================] - 16s - loss: 0.4585 - acc: 0.8626
Epoch 23/40
3400/3400 [==============================] - 16s - loss: 0.4338 - acc: 0.8644
Epoch 24/40
3400/3400 [==============================] - 16s - loss: 0.4139 - acc: 0.8756
Epoch 25/40
3400/3400 [==============================] - 16s - loss: 0.4320 - acc: 0.8706
Epoch 26/40
3400/3400 [==============================] - 16s - loss: 0.3958 - acc: 0.8812
Epoch 27/40
3400/3400 [==============================] - 16s - loss: 0.4127 - acc: 0.8771
Epoch 28/40
3400/3400 [==============================] - 16s - loss: 0.3934 - acc: 0.8815
Epoch 29/40
3400/3400 [==============================] - 18s - loss: 0.3744 - acc: 0.8844
Epoch 30/40
3400/3400 [==============================] - 17s - loss: 0.3500 - acc: 0.8921
Epoch 31/40
3400/3400 [==============================] - 18s - loss: 0.3258 - acc: 0.9074
Epoch 32/40
3400/3400 [==============================] - 17s - loss: 0.3734 - acc: 0.8897
Epoch 33/40
3400/3400 [==============================] - 16s - loss: 0.3217 - acc: 0.9044
Epoch 34/40
3400/3400 [==============================] - 16s - loss: 0.3187 - acc: 0.9021
Epoch 35/40
3400/3400 [==============================] - 16s - loss: 0.2869 - acc: 0.9112
Epoch 36/40
3400/3400 [==============================] - 16s - loss: 0.3107 - acc: 0.9068
Epoch 37/40
3400/3400 [==============================] - 18s - loss: 0.3401 - acc: 0.8985
Epoch 38/40
3400/3400 [==============================] - 20s - loss: 0.3100 - acc: 0.9085
Epoch 39/40
3400/3400 [==============================] - 16s - loss: 0.2920 - acc: 0.9132
Epoch 40/40
3400/3400 [==============================] - 20s - loss: 0.2957 - acc: 0.9138
train time : 681.127997
39104/39104 [==============================] - 77s
[ True  True  True ...,  True  True  True]
2016-07-11 08:31:17,610 : DEBUG : 正确的个数:38435
正确的个数:38435
准确率为:0.982892
2016-07-11 08:31:17,834 : DEBUG : 准确率为:0.982892
F1为：[ 0.98183214  0.98615137  0.98010511  0.99923739  0.99916318  0.98532962
  0.99933906  0.98727069  0.97736057  0.99900662  0.98296837  0.69981584
  0.98544396  0.84822695  1.          1.          0.99563319  1.
  0.85714286  0.97913323  0.9991357   0.95505618  0.98678414  0.97652582
  0.99295775  0.91646778  0.99137931  0.62068966  0.86086957  0.97688752
  0.99292453  0.99349241  0.99598394  0.7748184 ]
2016-07-11 08:31:17,867 : DEBUG : F1为：[ 0.98183214  0.98615137  0.98010511  0.99923739  0.99916318  0.98532962
  0.99933906  0.98727069  0.97736057  0.99900662  0.98296837  0.69981584
  0.98544396  0.84822695  1.          1.          0.99563319  1.
  0.85714286  0.97913323  0.9991357   0.95505618  0.98678414  0.97652582
  0.99295775  0.91646778  0.99137931  0.62068966  0.86086957  0.97688752
  0.99292453  0.99349241  0.99598394  0.7748184 ]
precision:[ 0.99817898  0.98646907  0.9992346   0.99912854  0.9996651   1.          1.
  0.99135338  0.99971759  1.          0.98536585  0.53977273  0.99558824
  0.74937343  1.          1.          0.99130435  1.          0.75496689
  0.97133758  1.          0.91397849  1.          0.96296296  1.
  0.84581498  0.98290598  0.45        0.7734375   0.97940268  0.99763033
  0.99565217  0.99332443  0.63492063]
recall_score:[ 0.96601208  0.98583387  0.96169429  0.99934626  0.99866176  0.97108346
  0.998679    0.98322148  0.95598164  0.99801522  0.98058252  0.9947644
  0.97550432  0.97712418  1.          1.          1.          1.
  0.99130435  0.98705502  0.99827288  1.          0.97391304  0.99047619
  0.98601399  1.          1.          1.          0.97058824  0.97438525
  0.98826291  0.99134199  0.99865772  0.99378882]
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
zeropadding2d_5 (ZeroPadding2D)  (None, 1, 17, 17)     0           zeropadding2d_input_3[0][0]
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 32, 15, 15)    320         zeropadding2d_5[0][0]
____________________________________________________________________________________________________
activation_13 (Activation)       (None, 32, 15, 15)    0           convolution2d_7[0][0]
____________________________________________________________________________________________________
maxpooling2d_5 (MaxPooling2D)    (None, 32, 7, 7)      0           activation_13[0][0]
____________________________________________________________________________________________________
zeropadding2d_6 (ZeroPadding2D)  (None, 32, 9, 9)      0           maxpooling2d_5[0][0]
____________________________________________________________________________________________________
convolution2d_8 (Convolution2D)  (None, 64, 7, 7)      18496       zeropadding2d_6[0][0]
____________________________________________________________________________________________________
activation_14 (Activation)       (None, 64, 7, 7)      0           convolution2d_8[0][0]
____________________________________________________________________________________________________
maxpooling2d_6 (MaxPooling2D)    (None, 64, 3, 3)      0           activation_14[0][0]
____________________________________________________________________________________________________
convolution2d_9 (Convolution2D)  (None, 128, 1, 1)     73856       maxpooling2d_6[0][0]
____________________________________________________________________________________________________
activation_15 (Activation)       (None, 128, 1, 1)     0           convolution2d_9[0][0]
____________________________________________________________________________________________________
flatten_3 (Flatten)              (None, 128)           0           activation_15[0][0]
____________________________________________________________________________________________________
dense_7 (Dense)                  (None, 100)           12900       flatten_3[0][0]
____________________________________________________________________________________________________
activation_16 (Activation)       (None, 100)           0           dense_7[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 100)           0           activation_16[0][0]
____________________________________________________________________________________________________
dense_8 (Dense)                  (None, 50)            5050        dropout_5[0][0]
____________________________________________________________________________________________________
activation_17 (Activation)       (None, 50)            0           dense_8[0][0]
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 50)            0           activation_17[0][0]
____________________________________________________________________________________________________
dense_9 (Dense)                  (None, 34)            1734        dropout_6[0][0]
____________________________________________________________________________________________________
activation_18 (Activation)       (None, 34)            0           dense_9[0][0]
====================================================================================================
Total params: 112356
____________________________________________________________________________________________________
None
Epoch 1/40
2400/2400 [==============================] - 17s - loss: 3.4804 - acc: 0.0442
Epoch 2/40
2400/2400 [==============================] - 14s - loss: 3.2394 - acc: 0.1046
Epoch 3/40
2400/2400 [==============================] - 15s - loss: 2.7797 - acc: 0.1867
Epoch 4/40
2400/2400 [==============================] - 15s - loss: 2.1487 - acc: 0.3496
Epoch 5/40
2400/2400 [==============================] - 14s - loss: 1.5549 - acc: 0.5067
Epoch 6/40
2400/2400 [==============================] - 15s - loss: 1.2820 - acc: 0.5675
Epoch 7/40
2400/2400 [==============================] - 16s - loss: 1.0393 - acc: 0.6692
Epoch 8/40
2400/2400 [==============================] - 16s - loss: 0.8402 - acc: 0.7238
Epoch 9/40
2400/2400 [==============================] - 15s - loss: 0.7301 - acc: 0.7671
Epoch 10/40
2400/2400 [==============================] - 16s - loss: 0.6655 - acc: 0.7829
Epoch 11/40
2400/2400 [==============================] - 14s - loss: 0.5346 - acc: 0.8321
Epoch 12/40
2400/2400 [==============================] - 15s - loss: 0.4953 - acc: 0.8362
Epoch 13/40
2400/2400 [==============================] - 15s - loss: 0.4590 - acc: 0.8654
Epoch 14/40
2400/2400 [==============================] - 17s - loss: 0.4156 - acc: 0.8746
Epoch 15/40
2400/2400 [==============================] - 15s - loss: 0.3670 - acc: 0.8904
Epoch 16/40
2400/2400 [==============================] - 15s - loss: 0.3871 - acc: 0.8775
Epoch 17/40
2400/2400 [==============================] - 15s - loss: 0.3664 - acc: 0.8988
Epoch 18/40
2400/2400 [==============================] - 15s - loss: 0.3760 - acc: 0.8958
Epoch 19/40
2400/2400 [==============================] - 15s - loss: 0.3127 - acc: 0.9108
Epoch 20/40
2400/2400 [==============================] - 15s - loss: 0.2938 - acc: 0.9133
Epoch 21/40
2400/2400 [==============================] - 15s - loss: 0.3055 - acc: 0.9171
Epoch 22/40
2400/2400 [==============================] - 15s - loss: 0.2798 - acc: 0.9183
Epoch 23/40
2400/2400 [==============================] - 15s - loss: 0.2652 - acc: 0.9271
Epoch 24/40
2400/2400 [==============================] - 14s - loss: 0.2665 - acc: 0.9200
Epoch 25/40
2400/2400 [==============================] - 15s - loss: 0.2674 - acc: 0.9258
Epoch 26/40
2400/2400 [==============================] - 15s - loss: 0.2597 - acc: 0.9242
Epoch 27/40
2400/2400 [==============================] - 15s - loss: 0.2368 - acc: 0.9308
Epoch 28/40
2400/2400 [==============================] - 16s - loss: 0.2646 - acc: 0.9225
Epoch 29/40
2400/2400 [==============================] - 15s - loss: 0.2393 - acc: 0.9375
Epoch 30/40
2400/2400 [==============================] - 16s - loss: 0.2167 - acc: 0.9437
Epoch 31/40
2400/2400 [==============================] - 17s - loss: 0.2065 - acc: 0.9442
Epoch 32/40
2400/2400 [==============================] - 15s - loss: 0.2219 - acc: 0.9354
Epoch 33/40
2400/2400 [==============================] - 15s - loss: 0.1960 - acc: 0.9425
Epoch 34/40
2400/2400 [==============================] - 16s - loss: 0.2098 - acc: 0.9367
Epoch 35/40
2400/2400 [==============================] - 18s - loss: 0.2082 - acc: 0.9408
Epoch 36/40
2400/2400 [==============================] - 19s - loss: 0.1978 - acc: 0.9450
Epoch 37/40
2400/2400 [==============================] - 16s - loss: 0.1838 - acc: 0.9488
Epoch 38/40
2400/2400 [==============================] - 15s - loss: 0.1939 - acc: 0.9425
Epoch 39/40
2400/2400 [==============================] - 13s - loss: 0.2096 - acc: 0.9404
Epoch 40/40
2400/2400 [==============================] - 17s - loss: 0.2111 - acc: 0.9400
train time : 641.386136
6568/6568 [==============================] - 15s
[ True  True False ...,  True  True  True]
2016-07-11 08:42:18,093 : DEBUG : 正确的个数:6497
正确的个数:6497
准确率为:0.989190
2016-07-11 08:42:18,148 : DEBUG : 准确率为:0.989190
2016-07-11 08:42:18,157 : DEBUG : F1为：[ 0.98777506  0.9974026   0.99127907  0.96969697  0.99570815  0.99574468
  0.99559471  1.          0.88163265  0.98709677  0.99827288  0.98837209
  0.98230088  0.97222222  0.99413834  1.          0.99137931  0.992
  0.98076923  0.98498187  0.99412456  0.99565217  0.99865952  0.99690402]
F1为：[ 0.98777506  0.9974026   0.99127907  0.96969697  0.99570815  0.99574468
  0.99559471  1.          0.88163265  0.98709677  0.99827288  0.98837209
  0.98230088  0.97222222  0.99413834  1.          0.99137931  0.992
  0.98076923  0.98498187  0.99412456  0.99565217  0.99865952  0.99690402]
precision:[ 0.99507389  0.99481865  1.          0.9470405   0.99145299  0.99152542
  1.          1.          0.83076923  0.98392283  0.99827288  0.97701149
  1.          0.95454545  1.          1.          0.98290598  1.
  0.96226415  0.99581152  0.99529412  1.          0.99732262  0.99382716]
recall_score:[ 0.98058252  1.          0.98270893  0.99346405  1.          1.
  0.99122807  1.          0.93913043  0.99029126  0.99827288  1.
  0.96521739  0.99056604  0.98834499  1.          1.          0.98412698
  1.          0.97438525  0.99295775  0.99134199  1.          1.        ]

Process finished with exit code 0
