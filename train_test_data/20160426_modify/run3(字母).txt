/usr/bin/python2.7 /home/jdwang/PycharmProjects/digitRecognition/cnn/cnn_train.py
Using Theano backend.
==============================
使用CNN网络对图片进行分类
==============================
start running!
2016-07-12 12:28:14,255 : DEBUG : ==============================
2016-07-12 12:28:14,255 : DEBUG : 使用CNN网络对图片进行分类
2016-07-12 12:28:14,255 : DEBUG : ==============================
2016-07-12 12:28:14,255 : DEBUG : start running!
2016-07-12 12:28:14,255 : DEBUG : ====================
24
2400
6806
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
zeropadding2d_1 (ZeroPadding2D)  (None, 1, 17, 17)     0           zeropadding2d_input_1[0][0]
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (None, 32, 15, 15)    320         zeropadding2d_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 32, 15, 15)    0           convolution2d_1[0][0]
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 32, 7, 7)      0           activation_1[0][0]
____________________________________________________________________________________________________
zeropadding2d_2 (ZeroPadding2D)  (None, 32, 9, 9)      0           maxpooling2d_1[0][0]
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 7, 7)      18496       zeropadding2d_2[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 64, 7, 7)      0           convolution2d_2[0][0]
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 64, 3, 3)      0           activation_2[0][0]
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 1, 1)     73856       maxpooling2d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 128, 1, 1)     0           convolution2d_3[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 128)           0           activation_3[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 100)           12900       flatten_1[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)        (None, 100)           0           dense_1[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 100)           0           activation_4[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 50)            5050        dropout_1[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)        (None, 50)            0           dense_2[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 50)            0           activation_5[0][0]
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 24)            1224        dropout_2[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)        (None, 24)            0           dense_3[0][0]
====================================================================================================
Total params: 111846
____________________________________________________________________________________________________
None
{'nb_epoch': 50, 'num_labels': 24, 'verbose': 1}
2016-07-12 12:28:16,350 : DEBUG : {'nb_epoch': 50, 'num_labels': 24, 'verbose': 1}
Epoch 1/50
2400/2400 [==============================] - 9s - loss: 3.1790 - acc: 0.0550
Epoch 2/50
2400/2400 [==============================] - 9s - loss: 2.9970 - acc: 0.1129
Epoch 3/50
2400/2400 [==============================] - 9s - loss: 2.6582 - acc: 0.1992
Epoch 4/50
2400/2400 [==============================] - 9s - loss: 2.1336 - acc: 0.3367
Epoch 5/50
2400/2400 [==============================] - 9s - loss: 1.6202 - acc: 0.4746
Epoch 6/50
2400/2400 [==============================] - 9s - loss: 1.2836 - acc: 0.5762
Epoch 7/50
2400/2400 [==============================] - 9s - loss: 0.9493 - acc: 0.6787
Epoch 8/50
2400/2400 [==============================] - 10s - loss: 0.7838 - acc: 0.7438
Epoch 9/50
2400/2400 [==============================] - 10s - loss: 0.6889 - acc: 0.7775
Epoch 10/50
2400/2400 [==============================] - 11s - loss: 0.5901 - acc: 0.8154
Epoch 11/50
2400/2400 [==============================] - 10s - loss: 0.5628 - acc: 0.8125
Epoch 12/50
2400/2400 [==============================] - 9s - loss: 0.5213 - acc: 0.8338
Epoch 13/50
2400/2400 [==============================] - 9s - loss: 0.4165 - acc: 0.8717
Epoch 14/50
2400/2400 [==============================] - 9s - loss: 0.4030 - acc: 0.8721
Epoch 15/50
2400/2400 [==============================] - 10s - loss: 0.3720 - acc: 0.8817
Epoch 16/50
2400/2400 [==============================] - 10s - loss: 0.3378 - acc: 0.8892
Epoch 17/50
2400/2400 [==============================] - 9s - loss: 0.3069 - acc: 0.8987
Epoch 18/50
2400/2400 [==============================] - 9s - loss: 0.2975 - acc: 0.9021
Epoch 19/50
2400/2400 [==============================] - 13s - loss: 0.2834 - acc: 0.9104
Epoch 20/50
2400/2400 [==============================] - 15s - loss: 0.2898 - acc: 0.9096
Epoch 21/50
2400/2400 [==============================] - 15s - loss: 0.2552 - acc: 0.9204
Epoch 22/50
2400/2400 [==============================] - 14s - loss: 0.2552 - acc: 0.9221
Epoch 23/50
2400/2400 [==============================] - 9s - loss: 0.2437 - acc: 0.9308
Epoch 24/50
2400/2400 [==============================] - 9s - loss: 0.2148 - acc: 0.9346
Epoch 25/50
2400/2400 [==============================] - 10s - loss: 0.1928 - acc: 0.9450
Epoch 26/50
2400/2400 [==============================] - 9s - loss: 0.1854 - acc: 0.9392
Epoch 27/50
2400/2400 [==============================] - 9s - loss: 0.2163 - acc: 0.9333
Epoch 28/50
2400/2400 [==============================] - 9s - loss: 0.1971 - acc: 0.9413
Epoch 29/50
2400/2400 [==============================] - 10s - loss: 0.1942 - acc: 0.9375
Epoch 30/50
2400/2400 [==============================] - 10s - loss: 0.1844 - acc: 0.9421
Epoch 31/50
2400/2400 [==============================] - 9s - loss: 0.1608 - acc: 0.9529
Epoch 32/50
2400/2400 [==============================] - 10s - loss: 0.1778 - acc: 0.9438
Epoch 33/50
2400/2400 [==============================] - 11s - loss: 0.1796 - acc: 0.9492
Epoch 34/50
2400/2400 [==============================] - 9s - loss: 0.1755 - acc: 0.9479
Epoch 35/50
2400/2400 [==============================] - 9s - loss: 0.1815 - acc: 0.9413
Epoch 36/50
2400/2400 [==============================] - 9s - loss: 0.1588 - acc: 0.9500
Epoch 37/50
2400/2400 [==============================] - 9s - loss: 0.1588 - acc: 0.9467
Epoch 38/50
2400/2400 [==============================] - 9s - loss: 0.1524 - acc: 0.9542
Epoch 39/50
2400/2400 [==============================] - 9s - loss: 0.1828 - acc: 0.9454
Epoch 40/50
2400/2400 [==============================] - 9s - loss: 0.1496 - acc: 0.9513
Epoch 41/50
2400/2400 [==============================] - 9s - loss: 0.1447 - acc: 0.9563
Epoch 42/50
2400/2400 [==============================] - 9s - loss: 0.1415 - acc: 0.9571
Epoch 43/50
2400/2400 [==============================] - 10s - loss: 0.1354 - acc: 0.9608
Epoch 44/50
2400/2400 [==============================] - 14s - loss: 0.1239 - acc: 0.9613
Epoch 45/50
2400/2400 [==============================] - 14s - loss: 0.1335 - acc: 0.9546
Epoch 46/50
2400/2400 [==============================] - 14s - loss: 0.1178 - acc: 0.9663
Epoch 47/50
2400/2400 [==============================] - 12s - loss: 0.1430 - acc: 0.9583
Epoch 48/50
2400/2400 [==============================] - 9s - loss: 0.1190 - acc: 0.9629
Epoch 49/50
2400/2400 [==============================] - 13s - loss: 0.1114 - acc: 0.9638
Epoch 50/50
2400/2400 [==============================] - 11s - loss: 0.1282 - acc: 0.9554
train time : 534.580056
6806/6806 [==============================] - 11s
[ True  True  True ...,  True  True  True]
2016-07-12 12:37:23,293 : DEBUG : 正确的个数:6758
正确的个数:6758
2016-07-12 12:37:23,335 : DEBUG : 准确率为:0.992947
准确率为:0.992947
2016-07-12 12:37:23,341 : DEBUG : F1为：[ 0.99262899  1.          0.99487179  0.98823529  1.          0.99574468
  0.99559471  1.          0.92682927  0.99842022  0.9991357   0.96590909
  0.97757848  0.98165138  0.99411072  1.          0.99137931  0.99465241
  0.99047619  0.98977505  0.99297424  1.          0.99799331  0.997543  ]
F1为：0.992629|1.000000|0.994872|0.988235|1.000000|0.995745|0.995595|1.000000|0.926829|0.998420|0.999136|0.965909|0.977578|0.981651|0.994111|1.000000|0.991379|0.994652|0.990476|0.989775|0.992974|1.000000|0.997993|0.997543
---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
precision:[ 1.          1.          1.          0.98181818  1.          0.99152542
  1.          1.          0.87022901  0.99684543  1.          0.93406593
  0.99090909  0.96396396  1.          1.          0.98290598  0.9893617   1.
  1.          0.98834499  1.          0.9973262   0.99509804]
precision为：1.000000|1.000000|1.000000|0.981818|1.000000|0.991525|1.000000|1.000000|0.870229|0.996845|1.000000|0.934066|0.990909|0.963964|1.000000|1.000000|0.982906|0.989362|1.000000|1.000000|0.988345|1.000000|0.997326|0.995098
2016-07-12 12:37:23,343 : DEBUG : precision:[ 1.          1.          1.          0.98181818  1.          0.99152542
  1.          1.          0.87022901  0.99684543  1.          0.93406593
  0.99090909  0.96396396  1.          1.          0.98290598  0.9893617   1.
  1.          0.98834499  1.          0.9973262   0.99509804]
recall:[ 0.98536585  1.          0.98979592  0.99473684  1.          1.
  0.99122807  1.          0.99130435  1.          0.99827288  1.
  0.96460177  1.          0.9882904   1.          1.          1.
  0.98113208  0.97975709  0.99764706  1.          0.99866131  1.        ]
recall为：0.985366|1.000000|0.989796|0.994737|1.000000|1.000000|0.991228|1.000000|0.991304|1.000000|0.998273|1.000000|0.964602|1.000000|0.988290|1.000000|1.000000|1.000000|0.981132|0.979757|0.997647|1.000000|0.998661|1.000000
2400
6806
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
zeropadding2d_3 (ZeroPadding2D)  (None, 1, 17, 17)     0           zeropadding2d_input_2[0][0]
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 32, 15, 15)    320         zeropadding2d_3[0][0]
____________________________________________________________________________________________________
activation_7 (Activation)        (None, 32, 15, 15)    0           convolution2d_4[0][0]
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 32, 7, 7)      0           activation_7[0][0]
____________________________________________________________________________________________________
zeropadding2d_4 (ZeroPadding2D)  (None, 32, 9, 9)      0           maxpooling2d_3[0][0]
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 64, 7, 7)      18496       zeropadding2d_4[0][0]
____________________________________________________________________________________________________
activation_8 (Activation)        (None, 64, 7, 7)      0           convolution2d_5[0][0]
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 64, 3, 3)      0           activation_8[0][0]
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 128, 1, 1)     73856       maxpooling2d_4[0][0]
____________________________________________________________________________________________________
activation_9 (Activation)        (None, 128, 1, 1)     0           convolution2d_6[0][0]
____________________________________________________________________________________________________
flatten_2 (Flatten)              (None, 128)           0           activation_9[0][0]
____________________________________________________________________________________________________
dense_4 (Dense)                  (None, 100)           12900       flatten_2[0][0]
____________________________________________________________________________________________________
activation_10 (Activation)       (None, 100)           0           dense_4[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 100)           0           activation_10[0][0]
____________________________________________________________________________________________________
dense_5 (Dense)                  (None, 50)            5050        dropout_3[0][0]
____________________________________________________________________________________________________
activation_11 (Activation)       (None, 50)            0           dense_5[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 50)            0           activation_11[0][0]
____________________________________________________________________________________________________
dense_6 (Dense)                  (None, 24)            1224        dropout_4[0][0]
____________________________________________________________________________________________________
activation_12 (Activation)       (None, 24)            0           dense_6[0][0]
====================================================================================================
Total params: 111846
____________________________________________________________________________________________________
None
2016-07-12 12:37:24,834 : DEBUG : {'nb_epoch': 50, 'num_labels': 24, 'verbose': 1}
{'nb_epoch': 50, 'num_labels': 24, 'verbose': 1}
Epoch 1/50
2400/2400 [==============================] - 10s - loss: 3.1773 - acc: 0.0537
Epoch 2/50
2400/2400 [==============================] - 11s - loss: 2.9583 - acc: 0.1163
Epoch 3/50
2400/2400 [==============================] - 13s - loss: 2.5221 - acc: 0.2429
Epoch 4/50
2400/2400 [==============================] - 12s - loss: 2.0052 - acc: 0.3750
Epoch 5/50
2400/2400 [==============================] - 9s - loss: 1.5068 - acc: 0.5171
Epoch 6/50
2400/2400 [==============================] - 9s - loss: 1.1772 - acc: 0.6100
Epoch 7/50
2400/2400 [==============================] - 9s - loss: 0.9577 - acc: 0.7050
Epoch 8/50
2400/2400 [==============================] - 9s - loss: 0.7570 - acc: 0.7571
Epoch 9/50
2400/2400 [==============================] - 9s - loss: 0.6730 - acc: 0.7908
Epoch 10/50
2400/2400 [==============================] - 9s - loss: 0.5719 - acc: 0.8337
Epoch 11/50
2400/2400 [==============================] - 9s - loss: 0.5329 - acc: 0.8229
Epoch 12/50
2400/2400 [==============================] - 9s - loss: 0.4709 - acc: 0.8567
Epoch 13/50
2400/2400 [==============================] - 9s - loss: 0.4369 - acc: 0.8608
Epoch 14/50
2400/2400 [==============================] - 9s - loss: 0.4060 - acc: 0.8775
Epoch 15/50
2400/2400 [==============================] - 9s - loss: 0.3941 - acc: 0.8737
Epoch 16/50
2400/2400 [==============================] - 9s - loss: 0.3471 - acc: 0.8888
Epoch 17/50
2400/2400 [==============================] - 9s - loss: 0.3319 - acc: 0.9038
Epoch 18/50
2400/2400 [==============================] - 9s - loss: 0.3275 - acc: 0.8883
Epoch 19/50
2400/2400 [==============================] - 9s - loss: 0.2781 - acc: 0.9100
Epoch 20/50
2400/2400 [==============================] - 9s - loss: 0.2993 - acc: 0.9017
Epoch 21/50
2400/2400 [==============================] - 9s - loss: 0.2479 - acc: 0.9233
Epoch 22/50
2400/2400 [==============================] - 9s - loss: 0.2728 - acc: 0.9117
Epoch 23/50
2400/2400 [==============================] - 9s - loss: 0.2477 - acc: 0.9246
Epoch 24/50
2400/2400 [==============================] - 9s - loss: 0.2375 - acc: 0.9292
Epoch 25/50
2400/2400 [==============================] - 9s - loss: 0.2292 - acc: 0.9333
Epoch 26/50
2400/2400 [==============================] - 9s - loss: 0.2028 - acc: 0.9371
Epoch 27/50
2400/2400 [==============================] - 9s - loss: 0.2174 - acc: 0.9346
Epoch 28/50
2400/2400 [==============================] - 9s - loss: 0.2091 - acc: 0.9313
Epoch 29/50
2400/2400 [==============================] - 9s - loss: 0.2087 - acc: 0.9321
Epoch 30/50
2400/2400 [==============================] - 9s - loss: 0.1992 - acc: 0.9400
Epoch 31/50
2400/2400 [==============================] - 9s - loss: 0.1910 - acc: 0.9392
Epoch 32/50
2400/2400 [==============================] - 9s - loss: 0.1849 - acc: 0.9417
Epoch 33/50
2400/2400 [==============================] - 9s - loss: 0.1786 - acc: 0.9471
Epoch 34/50
2400/2400 [==============================] - 9s - loss: 0.1587 - acc: 0.9442
Epoch 35/50
2400/2400 [==============================] - 9s - loss: 0.1628 - acc: 0.9512
Epoch 36/50
2400/2400 [==============================] - 9s - loss: 0.1658 - acc: 0.9467
Epoch 37/50
2400/2400 [==============================] - 9s - loss: 0.1845 - acc: 0.9521
Epoch 38/50
2400/2400 [==============================] - 9s - loss: 0.1566 - acc: 0.9483
Epoch 39/50
2400/2400 [==============================] - 9s - loss: 0.1494 - acc: 0.9550
Epoch 40/50
2400/2400 [==============================] - 9s - loss: 0.1636 - acc: 0.9450
Epoch 41/50
2400/2400 [==============================] - 9s - loss: 0.1412 - acc: 0.9563
Epoch 42/50
2400/2400 [==============================] - 9s - loss: 0.1414 - acc: 0.9513
Epoch 43/50
2400/2400 [==============================] - 9s - loss: 0.1408 - acc: 0.9575
Epoch 44/50
2400/2400 [==============================] - 9s - loss: 0.1324 - acc: 0.9596
Epoch 45/50
2400/2400 [==============================] - 9s - loss: 0.1336 - acc: 0.9583
Epoch 46/50
2400/2400 [==============================] - 9s - loss: 0.1377 - acc: 0.9617
Epoch 47/50
2400/2400 [==============================] - 9s - loss: 0.1162 - acc: 0.9663
Epoch 48/50
2400/2400 [==============================] - 9s - loss: 0.1281 - acc: 0.9588
Epoch 49/50
2400/2400 [==============================] - 9s - loss: 0.1597 - acc: 0.9550
Epoch 50/50
2400/2400 [==============================] - 9s - loss: 0.1588 - acc: 0.9563
train time : 474.152164
6806/6806 [==============================] - 9s
[ True  True  True ...,  True  True  True]
2016-07-12 12:45:29,079 : DEBUG : 正确的个数:6734
正确的个数:6734
2016-07-12 12:45:29,101 : DEBUG : 准确率为:0.989421
准确率为:0.989421
F1为：0.987835|1.000000|0.994879|0.984293|1.000000|0.979079|0.995595|1.000000|0.926230|0.990506|0.998273|0.949721|0.968610|0.977169|0.988152|1.000000|0.991379|0.994652|0.933921|0.989258|0.996458|1.000000|0.989872|1.000000
---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
2016-07-12 12:45:29,105 : DEBUG : F1为：[ 0.98783455  1.          0.9948793   0.98429319  1.          0.9790795
  0.99559471  1.          0.92622951  0.99050633  0.99827288  0.94972067
  0.96860987  0.97716895  0.98815166  1.          0.99137931  0.99465241
  0.9339207   0.98925831  0.99645809  1.          0.98987171  1.        ]
2016-07-12 12:45:29,107 : DEBUG : precision:[ 0.98543689  1.          0.99853157  0.97916667  1.          0.95901639
  1.          1.          0.87596899  0.99050633  0.99827288  0.90425532
  0.98181818  0.95535714  1.          1.          0.98290598  0.9893617
  0.87603306  1.          1.          1.          0.9986376   1.        ]
precision:[ 0.98543689  1.          0.99853157  0.97916667  1.          0.95901639
  1.          1.          0.87596899  0.99050633  0.99827288  0.90425532
  0.98181818  0.95535714  1.          1.          0.98290598  0.9893617
  0.87603306  1.          1.          1.          0.9986376   1.        ]
precision为：0.985437|1.000000|0.998532|0.979167|1.000000|0.959016|1.000000|1.000000|0.875969|0.990506|0.998273|0.904255|0.981818|0.955357|1.000000|1.000000|0.982906|0.989362|0.876033|1.000000|1.000000|1.000000|0.998638|1.000000
recall:[ 0.9902439   1.          0.99125364  0.98947368  1.          1.
  0.99122807  1.          0.9826087   0.99050633  0.99827288  1.
  0.95575221  1.          0.9765808   1.          1.          1.          1.
  0.97874494  0.99294118  1.          0.98125837  1.        ]
recall为：0.990244|1.000000|0.991254|0.989474|1.000000|1.000000|0.991228|1.000000|0.982609|0.990506|0.998273|1.000000|0.955752|1.000000|0.976581|1.000000|1.000000|1.000000|1.000000|0.978745|0.992941|1.000000|0.981258|1.000000
2400
6808
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
zeropadding2d_5 (ZeroPadding2D)  (None, 1, 17, 17)     0           zeropadding2d_input_3[0][0]
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 32, 15, 15)    320         zeropadding2d_5[0][0]
____________________________________________________________________________________________________
activation_13 (Activation)       (None, 32, 15, 15)    0           convolution2d_7[0][0]
____________________________________________________________________________________________________
maxpooling2d_5 (MaxPooling2D)    (None, 32, 7, 7)      0           activation_13[0][0]
____________________________________________________________________________________________________
zeropadding2d_6 (ZeroPadding2D)  (None, 32, 9, 9)      0           maxpooling2d_5[0][0]
____________________________________________________________________________________________________
convolution2d_8 (Convolution2D)  (None, 64, 7, 7)      18496       zeropadding2d_6[0][0]
____________________________________________________________________________________________________
activation_14 (Activation)       (None, 64, 7, 7)      0           convolution2d_8[0][0]
____________________________________________________________________________________________________
maxpooling2d_6 (MaxPooling2D)    (None, 64, 3, 3)      0           activation_14[0][0]
____________________________________________________________________________________________________
convolution2d_9 (Convolution2D)  (None, 128, 1, 1)     73856       maxpooling2d_6[0][0]
____________________________________________________________________________________________________
activation_15 (Activation)       (None, 128, 1, 1)     0           convolution2d_9[0][0]
____________________________________________________________________________________________________
flatten_3 (Flatten)              (None, 128)           0           activation_15[0][0]
____________________________________________________________________________________________________
dense_7 (Dense)                  (None, 100)           12900       flatten_3[0][0]
____________________________________________________________________________________________________
activation_16 (Activation)       (None, 100)           0           dense_7[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 100)           0           activation_16[0][0]
____________________________________________________________________________________________________
dense_8 (Dense)                  (None, 50)            5050        dropout_5[0][0]
____________________________________________________________________________________________________
activation_17 (Activation)       (None, 50)            0           dense_8[0][0]
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 50)            0           activation_17[0][0]
____________________________________________________________________________________________________
dense_9 (Dense)                  (None, 24)            1224        dropout_6[0][0]
____________________________________________________________________________________________________
activation_18 (Activation)       (None, 24)            0           dense_9[0][0]
====================================================================================================
Total params: 111846
____________________________________________________________________________________________________
None
{'nb_epoch': 50, 'num_labels': 24, 'verbose': 1}
2016-07-12 12:45:30,528 : DEBUG : {'nb_epoch': 50, 'num_labels': 24, 'verbose': 1}
Epoch 1/50
2400/2400 [==============================] - 9s - loss: 3.1768 - acc: 0.0592
Epoch 2/50
2400/2400 [==============================] - 9s - loss: 2.9114 - acc: 0.1250
Epoch 3/50
2400/2400 [==============================] - 9s - loss: 2.4030 - acc: 0.2642
Epoch 4/50
2400/2400 [==============================] - 9s - loss: 1.8197 - acc: 0.4300
Epoch 5/50
2400/2400 [==============================] - 9s - loss: 1.3880 - acc: 0.5392
Epoch 6/50
2400/2400 [==============================] - 9s - loss: 1.0922 - acc: 0.6442
Epoch 7/50
2400/2400 [==============================] - 9s - loss: 0.9235 - acc: 0.6921
Epoch 8/50
2400/2400 [==============================] - 9s - loss: 0.7901 - acc: 0.7529
Epoch 9/50
2400/2400 [==============================] - 9s - loss: 0.6658 - acc: 0.7908
Epoch 10/50
2400/2400 [==============================] - 9s - loss: 0.5805 - acc: 0.8225
Epoch 11/50
2400/2400 [==============================] - 9s - loss: 0.5223 - acc: 0.8312
Epoch 12/50
2400/2400 [==============================] - 9s - loss: 0.4824 - acc: 0.8517
Epoch 13/50
2400/2400 [==============================] - 9s - loss: 0.4632 - acc: 0.8542
Epoch 14/50
2400/2400 [==============================] - 9s - loss: 0.3673 - acc: 0.8883
Epoch 15/50
2400/2400 [==============================] - 9s - loss: 0.3534 - acc: 0.8925
Epoch 16/50
2400/2400 [==============================] - 9s - loss: 0.3614 - acc: 0.8929
Epoch 17/50
2400/2400 [==============================] - 9s - loss: 0.3241 - acc: 0.9029
Epoch 18/50
2400/2400 [==============================] - 9s - loss: 0.2953 - acc: 0.9171
Epoch 19/50
2400/2400 [==============================] - 9s - loss: 0.2731 - acc: 0.9208
Epoch 20/50
2400/2400 [==============================] - 9s - loss: 0.3200 - acc: 0.9075
Epoch 21/50
2400/2400 [==============================] - 9s - loss: 0.2733 - acc: 0.9121
Epoch 22/50
2400/2400 [==============================] - 9s - loss: 0.2369 - acc: 0.9300
Epoch 23/50
2400/2400 [==============================] - 9s - loss: 0.2517 - acc: 0.9267
Epoch 24/50
2400/2400 [==============================] - 9s - loss: 0.2315 - acc: 0.9287
Epoch 25/50
2400/2400 [==============================] - 9s - loss: 0.2244 - acc: 0.9342
Epoch 26/50
2400/2400 [==============================] - 9s - loss: 0.2107 - acc: 0.9450
Epoch 27/50
2400/2400 [==============================] - 9s - loss: 0.2195 - acc: 0.9258
Epoch 28/50
2400/2400 [==============================] - 9s - loss: 0.2222 - acc: 0.9312
Epoch 29/50
2400/2400 [==============================] - 9s - loss: 0.1898 - acc: 0.9438
Epoch 30/50
2400/2400 [==============================] - 9s - loss: 0.2032 - acc: 0.9383
Epoch 31/50
2400/2400 [==============================] - 9s - loss: 0.2080 - acc: 0.9346
Epoch 32/50
2400/2400 [==============================] - 9s - loss: 0.1974 - acc: 0.9358
Epoch 33/50
2400/2400 [==============================] - 9s - loss: 0.1857 - acc: 0.9463
Epoch 34/50
2400/2400 [==============================] - 9s - loss: 0.1744 - acc: 0.9450
Epoch 35/50
2400/2400 [==============================] - 9s - loss: 0.1731 - acc: 0.9496
Epoch 36/50
2400/2400 [==============================] - 9s - loss: 0.1622 - acc: 0.9488
Epoch 37/50
2400/2400 [==============================] - 9s - loss: 0.1518 - acc: 0.9550
Epoch 38/50
2400/2400 [==============================] - 9s - loss: 0.1667 - acc: 0.9487
Epoch 39/50
2400/2400 [==============================] - 9s - loss: 0.1741 - acc: 0.9471
Epoch 40/50
2400/2400 [==============================] - 9s - loss: 0.1713 - acc: 0.9467
Epoch 41/50
2400/2400 [==============================] - 9s - loss: 0.1625 - acc: 0.9550
Epoch 42/50
2400/2400 [==============================] - 9s - loss: 0.1716 - acc: 0.9458
Epoch 43/50
2400/2400 [==============================] - 9s - loss: 0.1685 - acc: 0.9483
Epoch 44/50
2400/2400 [==============================] - 9s - loss: 0.1552 - acc: 0.9500
Epoch 45/50
2400/2400 [==============================] - 9s - loss: 0.1491 - acc: 0.9587
Epoch 46/50
2400/2400 [==============================] - 9s - loss: 0.1437 - acc: 0.9567
Epoch 47/50
2400/2400 [==============================] - 9s - loss: 0.1396 - acc: 0.9600
Epoch 48/50
2400/2400 [==============================] - 9s - loss: 0.1213 - acc: 0.9633
Epoch 49/50
2400/2400 [==============================] - 9s - loss: 0.1244 - acc: 0.9613
Epoch 50/50
2400/2400 [==============================] - 9s - loss: 0.1421 - acc: 0.9575
train time : 462.767475
6808/6808 [==============================] - 9s
[ True  True  True ...,  True  True  True]
2016-07-12 12:53:23,427 : DEBUG : 正确的个数:6760
正确的个数:6760
准确率为:0.992949
2016-07-12 12:53:23,450 : DEBUG : 准确率为:0.992949
2016-07-12 12:53:23,454 : DEBUG : F1为：[ 0.99262899  1.          0.99414348  0.98697917  1.          1.          1.
F1为：0.992629|1.000000|0.994143|0.986979|1.000000|1.000000|1.000000|1.000000|0.907631|0.992076|0.999136|0.982659|0.986667|0.986175|0.996475|1.000000|0.991379|1.000000|0.971429|0.989291|0.996458|1.000000|0.999331|0.997543
  1.          0.90763052  0.99207607  0.9991357   0.98265896  0.98666667
  0.98617512  0.99647474  1.          0.99137931  1.          0.97142857
  0.98929118  0.99645809  1.          0.9993311   0.997543  ]
---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
precision:[ 1.          1.          0.99852941  0.97680412  1.          1.          1.
  1.          0.84328358  0.99365079  1.          0.96590909  1.
  0.97272727  1.          1.          0.98290598  1.          0.98076923
  0.99691675  1.          1.          0.9986631   0.99509804]
precision为：1.000000|1.000000|0.998529|0.976804|1.000000|1.000000|1.000000|1.000000|0.843284|0.993651|1.000000|0.965909|1.000000|0.972727|1.000000|1.000000|0.982906|1.000000|0.980769|0.996917|1.000000|1.000000|0.998663|0.995098
2016-07-12 12:53:23,456 : DEBUG : precision:[ 1.          1.          0.99852941  0.97680412  1.          1.          1.
  1.          0.84328358  0.99365079  1.          0.96590909  1.
  0.97272727  1.          1.          0.98290598  1.          0.98076923
  0.99691675  1.          1.          0.9986631   0.99509804]
recall:[ 0.98536585  1.          0.98979592  0.99736842  1.          1.          1.
  1.          0.9826087   0.99050633  0.99827288  1.          0.97368421
  1.          0.99297424  1.          1.          1.          0.96226415
  0.98178138  0.99294118  1.          1.          1.        ]
recall为：0.985366|1.000000|0.989796|0.997368|1.000000|1.000000|1.000000|1.000000|0.982609|0.990506|0.998273|1.000000|0.973684|1.000000|0.992974|1.000000|1.000000|1.000000|0.962264|0.981781|0.992941|1.000000|1.000000|1.000000
end! Running time:1509s!
2016-07-12 12:53:23,477 : DEBUG : ====================
2016-07-12 12:53:23,477 : DEBUG : end! Running time:1509s!

Process finished with exit code 0
