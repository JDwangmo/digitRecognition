/usr/bin/python2.7 /home/jdwang/PycharmProjects/digitRecognition/cnn/cnn_train.py
Using Theano backend.
2400
6565
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
zeropadding2d_1 (ZeroPadding2D)  (None, 1, 17, 17)     0           zeropadding2d_input_1[0][0]
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (None, 32, 15, 15)    320         zeropadding2d_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 32, 15, 15)    0           convolution2d_1[0][0]
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 32, 7, 7)      0           activation_1[0][0]
____________________________________________________________________________________________________
zeropadding2d_2 (ZeroPadding2D)  (None, 32, 9, 9)      0           maxpooling2d_1[0][0]
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 7, 7)      18496       zeropadding2d_2[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 64, 7, 7)      0           convolution2d_2[0][0]
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 64, 3, 3)      0           activation_2[0][0]
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 1, 1)     73856       maxpooling2d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 128, 1, 1)     0           convolution2d_3[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 128)           0           activation_3[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 100)           12900       flatten_1[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)        (None, 100)           0           dense_1[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 100)           0           activation_4[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 50)            5050        dropout_1[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)        (None, 50)            0           dense_2[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 50)            0           activation_5[0][0]
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 24)            1224        dropout_2[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)        (None, 24)            0           dense_3[0][0]
====================================================================================================
Total params: 111846
____________________________________________________________________________________________________
None
Epoch 1/40
2400/2400 [==============================] - 15s - loss: 3.1553 - acc: 0.0621
Epoch 2/40
2400/2400 [==============================] - 15s - loss: 2.8810 - acc: 0.1463
Epoch 3/40
2400/2400 [==============================] - 15s - loss: 2.3834 - acc: 0.2696
Epoch 4/40
2400/2400 [==============================] - 15s - loss: 1.8449 - acc: 0.4129
Epoch 5/40
2400/2400 [==============================] - 16s - loss: 1.3943 - acc: 0.5525
Epoch 6/40
2400/2400 [==============================] - 16s - loss: 1.0938 - acc: 0.6417
Epoch 7/40
2400/2400 [==============================] - 15s - loss: 0.9009 - acc: 0.7167
Epoch 8/40
2400/2400 [==============================] - 16s - loss: 0.7752 - acc: 0.7450
Epoch 9/40
2400/2400 [==============================] - 16s - loss: 0.6922 - acc: 0.7821
Epoch 10/40
2400/2400 [==============================] - 16s - loss: 0.6229 - acc: 0.7987
Epoch 11/40
2400/2400 [==============================] - 15s - loss: 0.5690 - acc: 0.8329
Epoch 12/40
2400/2400 [==============================] - 17s - loss: 0.4691 - acc: 0.8521
Epoch 13/40
2400/2400 [==============================] - 15s - loss: 0.4436 - acc: 0.8675
Epoch 14/40
2400/2400 [==============================] - 17s - loss: 0.4068 - acc: 0.8837
Epoch 15/40
2400/2400 [==============================] - 15s - loss: 0.3919 - acc: 0.8825
Epoch 16/40
2400/2400 [==============================] - 16s - loss: 0.3818 - acc: 0.8833
Epoch 17/40
2400/2400 [==============================] - 14s - loss: 0.3402 - acc: 0.8987
Epoch 18/40
2400/2400 [==============================] - 16s - loss: 0.3368 - acc: 0.9042
Epoch 19/40
2400/2400 [==============================] - 16s - loss: 0.3015 - acc: 0.9075
Epoch 20/40
2400/2400 [==============================] - 15s - loss: 0.3130 - acc: 0.9054
Epoch 21/40
2400/2400 [==============================] - 16s - loss: 0.3053 - acc: 0.9088
Epoch 22/40
2400/2400 [==============================] - 15s - loss: 0.2931 - acc: 0.9146
Epoch 23/40
2400/2400 [==============================] - 16s - loss: 0.2805 - acc: 0.9229
Epoch 24/40
2400/2400 [==============================] - 16s - loss: 0.2704 - acc: 0.9196
Epoch 25/40
2400/2400 [==============================] - 16s - loss: 0.2753 - acc: 0.9221
Epoch 26/40
2400/2400 [==============================] - 16s - loss: 0.2461 - acc: 0.9292
Epoch 27/40
2400/2400 [==============================] - 16s - loss: 0.2275 - acc: 0.9388
Epoch 28/40
2400/2400 [==============================] - 15s - loss: 0.2308 - acc: 0.9304
Epoch 29/40
2400/2400 [==============================] - 15s - loss: 0.2350 - acc: 0.9317
Epoch 30/40
2400/2400 [==============================] - 17s - loss: 0.2155 - acc: 0.9392
Epoch 31/40
2400/2400 [==============================] - 17s - loss: 0.2191 - acc: 0.9396
Epoch 32/40
2400/2400 [==============================] - 17s - loss: 0.2055 - acc: 0.9413
Epoch 33/40
2400/2400 [==============================] - 16s - loss: 0.1968 - acc: 0.9396
Epoch 34/40
2400/2400 [==============================] - 13s - loss: 0.1801 - acc: 0.9450
Epoch 35/40
2400/2400 [==============================] - 18s - loss: 0.2157 - acc: 0.9438
Epoch 36/40
2400/2400 [==============================] - 19s - loss: 0.1828 - acc: 0.9458
Epoch 37/40
2400/2400 [==============================] - 16s - loss: 0.1841 - acc: 0.9462
Epoch 38/40
2400/2400 [==============================] - 15s - loss: 0.1825 - acc: 0.9433
Epoch 39/40
2400/2400 [==============================] - 16s - loss: 0.1874 - acc: 0.9508
Epoch 40/40
2400/2400 [==============================] - 15s - loss: 0.1745 - acc: 0.9492
train time : 653.609352
6565/6565 [==============================] - 15s
[ True  True  True ...,  True  True  True]
2016-07-11 08:42:17,074 : DEBUG : 正确的个数:6491
正确的个数:6491
2016-07-11 08:42:17,112 : DEBUG : 准确率为:0.988728
准确率为:0.988728
2016-07-11 08:42:17,117 : DEBUG : F1为：[ 0.98771499  1.          0.98695652  0.96214511  1.          0.99570815
  1.          1.          0.91497976  0.98397436  0.99827288  0.98837209
  0.96460177  0.97222222  0.99413834  0.99738903  0.995671    0.992
  0.97058824  0.98650052  0.99646643  0.99565217  0.99664655  0.99690402]
F1为：[ 0.98771499  1.          0.98695652  0.96214511  1.          0.99570815
  1.          1.          0.91497976  0.98397436  0.99827288  0.98837209
  0.96460177  0.97222222  0.99413834  0.99738903  0.995671    0.992
  0.97058824  0.98650052  0.99646643  0.99565217  0.99664655  0.99690402]
precision:[ 1.          1.          0.99271137  0.92987805  1.          1.          1.
  1.          0.85606061  0.97460317  0.99827288  0.97701149  0.98198198
  0.94594595  1.          1.          0.99137931  1.          0.97058824
  1.          1.          1.          0.99597855  0.99382716]
recall_score:[ 0.97572816  1.          0.98126801  0.99673203  1.          0.99145299
  1.          1.          0.9826087   0.99352751  0.99827288  1.
  0.94782609  1.          0.98834499  0.99479167  1.          0.98412698
  0.97058824  0.97336066  0.99295775  0.99134199  0.99731544  1.        ]
2400
6565
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
zeropadding2d_3 (ZeroPadding2D)  (None, 1, 17, 17)     0           zeropadding2d_input_2[0][0]
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 32, 15, 15)    320         zeropadding2d_3[0][0]
____________________________________________________________________________________________________
activation_7 (Activation)        (None, 32, 15, 15)    0           convolution2d_4[0][0]
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 32, 7, 7)      0           activation_7[0][0]
____________________________________________________________________________________________________
zeropadding2d_4 (ZeroPadding2D)  (None, 32, 9, 9)      0           maxpooling2d_3[0][0]
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 64, 7, 7)      18496       zeropadding2d_4[0][0]
____________________________________________________________________________________________________
activation_8 (Activation)        (None, 64, 7, 7)      0           convolution2d_5[0][0]
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 64, 3, 3)      0           activation_8[0][0]
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 128, 1, 1)     73856       maxpooling2d_4[0][0]
____________________________________________________________________________________________________
activation_9 (Activation)        (None, 128, 1, 1)     0           convolution2d_6[0][0]
____________________________________________________________________________________________________
flatten_2 (Flatten)              (None, 128)           0           activation_9[0][0]
____________________________________________________________________________________________________
dense_4 (Dense)                  (None, 100)           12900       flatten_2[0][0]
____________________________________________________________________________________________________
activation_10 (Activation)       (None, 100)           0           dense_4[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 100)           0           activation_10[0][0]
____________________________________________________________________________________________________
dense_5 (Dense)                  (None, 50)            5050        dropout_3[0][0]
____________________________________________________________________________________________________
activation_11 (Activation)       (None, 50)            0           dense_5[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 50)            0           activation_11[0][0]
____________________________________________________________________________________________________
dense_6 (Dense)                  (None, 24)            1224        dropout_4[0][0]
____________________________________________________________________________________________________
activation_12 (Activation)       (None, 24)            0           dense_6[0][0]
====================================================================================================
Total params: 111846
____________________________________________________________________________________________________
None
Epoch 1/40
2400/2400 [==============================] - 11s - loss: 3.1608 - acc: 0.0608
Epoch 2/40
2400/2400 [==============================] - 11s - loss: 3.0183 - acc: 0.1133
Epoch 3/40
2400/2400 [==============================] - 11s - loss: 2.5806 - acc: 0.2446
Epoch 4/40
2400/2400 [==============================] - 10s - loss: 2.0146 - acc: 0.3688
Epoch 5/40
2400/2400 [==============================] - 10s - loss: 1.5290 - acc: 0.5096
Epoch 6/40
2400/2400 [==============================] - 10s - loss: 1.1913 - acc: 0.6037
Epoch 7/40
2400/2400 [==============================] - 10s - loss: 0.9768 - acc: 0.6850
Epoch 8/40
2400/2400 [==============================] - 11s - loss: 0.8368 - acc: 0.7358
Epoch 9/40
2400/2400 [==============================] - 10s - loss: 0.6762 - acc: 0.7950
Epoch 10/40
2400/2400 [==============================] - 10s - loss: 0.6053 - acc: 0.8012
Epoch 11/40
2400/2400 [==============================] - 9s - loss: 0.5356 - acc: 0.8425
Epoch 12/40
2400/2400 [==============================] - 10s - loss: 0.4736 - acc: 0.8587
Epoch 13/40
2400/2400 [==============================] - 10s - loss: 0.4576 - acc: 0.8696
Epoch 14/40
2400/2400 [==============================] - 10s - loss: 0.4132 - acc: 0.8796
Epoch 15/40
2400/2400 [==============================] - 9s - loss: 0.3580 - acc: 0.8971
Epoch 16/40
2400/2400 [==============================] - 11s - loss: 0.3471 - acc: 0.9008
Epoch 17/40
2400/2400 [==============================] - 11s - loss: 0.3197 - acc: 0.9163
Epoch 18/40
2400/2400 [==============================] - 10s - loss: 0.3129 - acc: 0.9067
Epoch 19/40
2400/2400 [==============================] - 9s - loss: 0.2988 - acc: 0.9146
Epoch 20/40
2400/2400 [==============================] - 9s - loss: 0.2459 - acc: 0.9254
Epoch 21/40
2400/2400 [==============================] - 9s - loss: 0.2408 - acc: 0.9279
Epoch 22/40
2400/2400 [==============================] - 9s - loss: 0.2613 - acc: 0.9246
Epoch 23/40
2400/2400 [==============================] - 9s - loss: 0.2361 - acc: 0.9379
Epoch 24/40
2400/2400 [==============================] - 9s - loss: 0.2332 - acc: 0.9321
Epoch 25/40
2400/2400 [==============================] - 9s - loss: 0.2348 - acc: 0.9329
Epoch 26/40
2400/2400 [==============================] - 9s - loss: 0.2282 - acc: 0.9267
Epoch 27/40
2400/2400 [==============================] - 9s - loss: 0.2242 - acc: 0.9354
Epoch 28/40
2400/2400 [==============================] - 9s - loss: 0.2017 - acc: 0.9417
Epoch 29/40
2400/2400 [==============================] - 9s - loss: 0.2170 - acc: 0.9321
Epoch 30/40
2400/2400 [==============================] - 9s - loss: 0.1935 - acc: 0.9396
Epoch 31/40
2400/2400 [==============================] - 9s - loss: 0.2021 - acc: 0.9396
Epoch 32/40
2400/2400 [==============================] - 9s - loss: 0.1947 - acc: 0.9433
Epoch 33/40
2400/2400 [==============================] - 10s - loss: 0.1942 - acc: 0.9463
Epoch 34/40
2400/2400 [==============================] - 9s - loss: 0.1683 - acc: 0.9512
Epoch 35/40
2400/2400 [==============================] - 9s - loss: 0.1769 - acc: 0.9462
Epoch 36/40
2400/2400 [==============================] - 10s - loss: 0.1619 - acc: 0.9571
Epoch 37/40
2400/2400 [==============================] - 9s - loss: 0.1555 - acc: 0.9571
Epoch 38/40
2400/2400 [==============================] - 10s - loss: 0.1700 - acc: 0.9496
Epoch 39/40
2400/2400 [==============================] - 9s - loss: 0.1644 - acc: 0.9500
Epoch 40/40
2400/2400 [==============================] - 10s - loss: 0.1668 - acc: 0.9500
train time : 415.117235
6560/6565 [============================>.] - ETA: 0s[ True  True False ...,  True  True  True]
2016-07-11 08:49:25,206 : DEBUG : 正确的个数:6492
正确的个数:6492
准确率为:0.988880
2016-07-11 08:49:25,230 : DEBUG : 准确率为:0.988880
2016-07-11 08:49:25,234 : DEBUG : F1为：[ 0.98783455  0.99738903  0.99054545  0.96825397  1.          1.
  0.99559471  1.          0.90983607  0.98228663  0.99827288  1.
  0.97321429  0.96296296  0.99061033  0.99738903  0.99137931  0.99212598
  0.97087379  0.98604651  0.99292453  0.99565217  0.99732262  1.        ]
F1为：[ 0.98783455  0.99738903  0.99054545  0.96825397  1.          1.
  0.99559471  1.          0.90983607  0.98228663  0.99827288  1.
  0.97321429  0.96296296  0.99061033  0.99738903  0.99137931  0.99212598
  0.97087379  0.98604651  0.99292453  0.99565217  0.99732262  1.        ]
precision:[ 0.9902439   0.99479167  1.          0.94135802  1.          1.          1.
  1.          0.86046512  0.9775641   0.99827288  1.          1.
  0.93693694  0.99763593  1.          0.98290598  0.984375    0.96153846
  0.99478624  0.99763033  1.          0.99465955  1.        ]
recall_score:[ 0.98543689  1.          0.98126801  0.99673203  1.          1.
  0.99122807  1.          0.96521739  0.98705502  0.99827288  1.
  0.94782609  0.99047619  0.98368298  0.99479167  1.          1.
  0.98039216  0.97745902  0.98826291  0.99134199  1.          1.        ]
2400
6568
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
zeropadding2d_5 (ZeroPadding2D)  (None, 1, 17, 17)     0           zeropadding2d_input_3[0][0]
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 32, 15, 15)    320         zeropadding2d_5[0][0]
____________________________________________________________________________________________________
activation_13 (Activation)       (None, 32, 15, 15)    0           convolution2d_7[0][0]
____________________________________________________________________________________________________
maxpooling2d_5 (MaxPooling2D)    (None, 32, 7, 7)      0           activation_13[0][0]
____________________________________________________________________________________________________
zeropadding2d_6 (ZeroPadding2D)  (None, 32, 9, 9)      0           maxpooling2d_5[0][0]
____________________________________________________________________________________________________
convolution2d_8 (Convolution2D)  (None, 64, 7, 7)      18496       zeropadding2d_6[0][0]
____________________________________________________________________________________________________
activation_14 (Activation)       (None, 64, 7, 7)      0           convolution2d_8[0][0]
____________________________________________________________________________________________________
maxpooling2d_6 (MaxPooling2D)    (None, 64, 3, 3)      0           activation_14[0][0]
____________________________________________________________________________________________________
convolution2d_9 (Convolution2D)  (None, 128, 1, 1)     73856       maxpooling2d_6[0][0]
____________________________________________________________________________________________________
activation_15 (Activation)       (None, 128, 1, 1)     0           convolution2d_9[0][0]
____________________________________________________________________________________________________
flatten_3 (Flatten)              (None, 128)           0           activation_15[0][0]
____________________________________________________________________________________________________
dense_7 (Dense)                  (None, 100)           12900       flatten_3[0][0]
____________________________________________________________________________________________________
activation_16 (Activation)       (None, 100)           0           dense_7[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 100)           0           activation_16[0][0]
____________________________________________________________________________________________________
dense_8 (Dense)                  (None, 50)            5050        dropout_5[0][0]
____________________________________________________________________________________________________
activation_17 (Activation)       (None, 50)            0           dense_8[0][0]
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 50)            0           activation_17[0][0]
____________________________________________________________________________________________________
dense_9 (Dense)                  (None, 24)            1224        dropout_6[0][0]
____________________________________________________________________________________________________
activation_18 (Activation)       (None, 24)            0           dense_9[0][0]
====================================================================================================
Total params: 111846
____________________________________________________________________________________________________
None
Epoch 1/40
2400/2400 [==============================] - 10s - loss: 3.1620 - acc: 0.0529
Epoch 2/40
2400/2400 [==============================] - 9s - loss: 2.9817 - acc: 0.1146
Epoch 3/40
2400/2400 [==============================] - 9s - loss: 2.5347 - acc: 0.2562
Epoch 4/40
2400/2400 [==============================] - 9s - loss: 2.0435 - acc: 0.3679
Epoch 5/40
2400/2400 [==============================] - 9s - loss: 1.5565 - acc: 0.5025
Epoch 6/40
2400/2400 [==============================] - 10s - loss: 1.2874 - acc: 0.5837
Epoch 7/40
2400/2400 [==============================] - 10s - loss: 0.9746 - acc: 0.6838
Epoch 8/40
2400/2400 [==============================] - 9s - loss: 0.8089 - acc: 0.7408
Epoch 9/40
2400/2400 [==============================] - 10s - loss: 0.7090 - acc: 0.7829
Epoch 10/40
2400/2400 [==============================] - 10s - loss: 0.6404 - acc: 0.8121
Epoch 11/40
2400/2400 [==============================] - 11s - loss: 0.5575 - acc: 0.8371
Epoch 12/40
2400/2400 [==============================] - 11s - loss: 0.4721 - acc: 0.8600
Epoch 13/40
2400/2400 [==============================] - 10s - loss: 0.4342 - acc: 0.8746
Epoch 14/40
2400/2400 [==============================] - 10s - loss: 0.4025 - acc: 0.8842
Epoch 15/40
2400/2400 [==============================] - 9s - loss: 0.3749 - acc: 0.8904
Epoch 16/40
2400/2400 [==============================] - 9s - loss: 0.3702 - acc: 0.8917
Epoch 17/40
2400/2400 [==============================] - 9s - loss: 0.3458 - acc: 0.9029
Epoch 18/40
2400/2400 [==============================] - 10s - loss: 0.3233 - acc: 0.9142
Epoch 19/40
2400/2400 [==============================] - 9s - loss: 0.3036 - acc: 0.9158
Epoch 20/40
2400/2400 [==============================] - 10s - loss: 0.2900 - acc: 0.9225
Epoch 21/40
2400/2400 [==============================] - 11s - loss: 0.2821 - acc: 0.9138
Epoch 22/40
2400/2400 [==============================] - 10s - loss: 0.2696 - acc: 0.9246
Epoch 23/40
2400/2400 [==============================] - 10s - loss: 0.2586 - acc: 0.9271
Epoch 24/40
2400/2400 [==============================] - 10s - loss: 0.2499 - acc: 0.9267
Epoch 25/40
2400/2400 [==============================] - 11s - loss: 0.2519 - acc: 0.9283
Epoch 26/40
2400/2400 [==============================] - 11s - loss: 0.2419 - acc: 0.9350
Epoch 27/40
2400/2400 [==============================] - 10s - loss: 0.2324 - acc: 0.9313
Epoch 28/40
2400/2400 [==============================] - 10s - loss: 0.2353 - acc: 0.9337
Epoch 29/40
2400/2400 [==============================] - 10s - loss: 0.2144 - acc: 0.9388
Epoch 30/40
2400/2400 [==============================] - 9s - loss: 0.2328 - acc: 0.9358
Epoch 31/40
2400/2400 [==============================] - 10s - loss: 0.2320 - acc: 0.9333
Epoch 32/40
2400/2400 [==============================] - 11s - loss: 0.2203 - acc: 0.9329
Epoch 33/40
2400/2400 [==============================] - 10s - loss: 0.1986 - acc: 0.9421
Epoch 34/40
2400/2400 [==============================] - 10s - loss: 0.2077 - acc: 0.9454
Epoch 35/40
2400/2400 [==============================] - 10s - loss: 0.1921 - acc: 0.9496
Epoch 36/40
2400/2400 [==============================] - 10s - loss: 0.1892 - acc: 0.9404
Epoch 37/40
2400/2400 [==============================] - 10s - loss: 0.1891 - acc: 0.9504
Epoch 38/40
2400/2400 [==============================] - 10s - loss: 0.1987 - acc: 0.9438
Epoch 39/40
2400/2400 [==============================] - 10s - loss: 0.1901 - acc: 0.9496
Epoch 40/40
2400/2400 [==============================] - 10s - loss: 0.1947 - acc: 0.9429
train time : 414.816094
6568/6568 [==============================] - 11s
[ True  True False ...,  True  True  True]
2016-07-11 08:56:33,175 : DEBUG : 正确的个数:6499
正确的个数:6499
准确率为:0.989495
2016-07-11 08:56:33,210 : DEBUG : 准确率为:0.989495
2016-07-11 08:56:33,217 : DEBUG : F1为：[ 0.98777506  0.9974026   0.99127907  0.97124601  0.98701299  0.99152542
  0.99559471  1.          0.89411765  0.99032258  0.9991357   0.99415205
  0.98230088  0.97222222  0.99297424  1.          0.99137931  0.992
  0.97560976  0.98702647  0.99179367  0.99565217  0.99798793  1.        ]
F1为：[ 0.98777506  0.9974026   0.99127907  0.97124601  0.98701299  0.99152542
  0.99559471  1.          0.89411765  0.99032258  0.9991357   0.99415205
  0.98230088  0.97222222  0.99297424  1.          0.99137931  0.992
  0.97560976  0.98702647  0.99179367  0.99565217  0.99798793  1.        ]
precision:[ 0.99507389  0.99481865  1.          0.95        0.99130435  0.98319328
  1.          1.          0.81428571  0.98713826  1.          0.98837209
  1.          0.95454545  0.99764706  1.          0.98290598  1.
  0.97087379  1.          0.99063232  1.          0.99731903  1.        ]
recall_score:[ 0.98058252  1.          0.98270893  0.99346405  0.98275862  1.
  0.99122807  1.          0.99130435  0.99352751  0.99827288  1.
  0.96521739  0.99056604  0.98834499  1.          1.          0.98412698
  0.98039216  0.97438525  0.99295775  0.99134199  0.99865772  1.        ]

Process finished with exit code 0
